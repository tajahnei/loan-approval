{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load, Format and Inspect Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already up-to-date: imbalanced-learn in /Users/tajahneiwilliams/opt/anaconda3/envs/PythonAdv/lib/python3.6/site-packages (0.7.0)\r\n",
      "Requirement already satisfied, skipping upgrade: numpy>=1.13.3 in /Users/tajahneiwilliams/opt/anaconda3/envs/PythonAdv/lib/python3.6/site-packages (from imbalanced-learn) (1.18.5)\r\n",
      "Requirement already satisfied, skipping upgrade: scikit-learn>=0.23 in /Users/tajahneiwilliams/opt/anaconda3/envs/PythonAdv/lib/python3.6/site-packages (from imbalanced-learn) (0.23.1)\r\n",
      "Requirement already satisfied, skipping upgrade: scipy>=0.19.1 in /Users/tajahneiwilliams/opt/anaconda3/envs/PythonAdv/lib/python3.6/site-packages (from imbalanced-learn) (1.5.0)\r\n",
      "Requirement already satisfied, skipping upgrade: joblib>=0.11 in /Users/tajahneiwilliams/opt/anaconda3/envs/PythonAdv/lib/python3.6/site-packages (from imbalanced-learn) (0.15.1)\r\n",
      "Requirement already satisfied, skipping upgrade: threadpoolctl>=2.0.0 in /Users/tajahneiwilliams/opt/anaconda3/envs/PythonAdv/lib/python3.6/site-packages (from scikit-learn>=0.23->imbalanced-learn) (2.1.0)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install -U imbalanced-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import preprocessing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read Csv files using Pandas\n",
    "\n",
    "data = pd.read_csv('germanHeaders.csv', header= None)\n",
    "data_numeric = pd.read_csv('germancredit.csv', header= None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Store Column names\n",
    "columns = data.iloc[0].tolist()\n",
    "data.columns = columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop number headers and replace with descriptive headers\n",
    "data = data.iloc[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NaN</th>\n",
       "      <th>account_status</th>\n",
       "      <th>duration</th>\n",
       "      <th>credit_history</th>\n",
       "      <th>purpose</th>\n",
       "      <th>credit_amount</th>\n",
       "      <th>savings_account</th>\n",
       "      <th>unemployed</th>\n",
       "      <th>installment_rate</th>\n",
       "      <th>personal_status_sex</th>\n",
       "      <th>...</th>\n",
       "      <th>property</th>\n",
       "      <th>age</th>\n",
       "      <th>other_installment_plans</th>\n",
       "      <th>housing</th>\n",
       "      <th>credits</th>\n",
       "      <th>job</th>\n",
       "      <th>liable_for</th>\n",
       "      <th>telephone</th>\n",
       "      <th>foreign_worker</th>\n",
       "      <th>good/bad</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>A11</td>\n",
       "      <td>6</td>\n",
       "      <td>A34</td>\n",
       "      <td>A43</td>\n",
       "      <td>1169</td>\n",
       "      <td>A65</td>\n",
       "      <td>A75</td>\n",
       "      <td>4</td>\n",
       "      <td>A93</td>\n",
       "      <td>...</td>\n",
       "      <td>A121</td>\n",
       "      <td>67</td>\n",
       "      <td>A143</td>\n",
       "      <td>A152</td>\n",
       "      <td>2</td>\n",
       "      <td>A173</td>\n",
       "      <td>1</td>\n",
       "      <td>A192</td>\n",
       "      <td>A201</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>A12</td>\n",
       "      <td>48</td>\n",
       "      <td>A32</td>\n",
       "      <td>A43</td>\n",
       "      <td>5951</td>\n",
       "      <td>A61</td>\n",
       "      <td>A73</td>\n",
       "      <td>2</td>\n",
       "      <td>A92</td>\n",
       "      <td>...</td>\n",
       "      <td>A121</td>\n",
       "      <td>22</td>\n",
       "      <td>A143</td>\n",
       "      <td>A152</td>\n",
       "      <td>1</td>\n",
       "      <td>A173</td>\n",
       "      <td>1</td>\n",
       "      <td>A191</td>\n",
       "      <td>A201</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.0</td>\n",
       "      <td>A14</td>\n",
       "      <td>12</td>\n",
       "      <td>A34</td>\n",
       "      <td>A46</td>\n",
       "      <td>2096</td>\n",
       "      <td>A61</td>\n",
       "      <td>A74</td>\n",
       "      <td>2</td>\n",
       "      <td>A93</td>\n",
       "      <td>...</td>\n",
       "      <td>A121</td>\n",
       "      <td>49</td>\n",
       "      <td>A143</td>\n",
       "      <td>A152</td>\n",
       "      <td>1</td>\n",
       "      <td>A172</td>\n",
       "      <td>2</td>\n",
       "      <td>A191</td>\n",
       "      <td>A201</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.0</td>\n",
       "      <td>A11</td>\n",
       "      <td>42</td>\n",
       "      <td>A32</td>\n",
       "      <td>A42</td>\n",
       "      <td>7882</td>\n",
       "      <td>A61</td>\n",
       "      <td>A74</td>\n",
       "      <td>2</td>\n",
       "      <td>A93</td>\n",
       "      <td>...</td>\n",
       "      <td>A122</td>\n",
       "      <td>45</td>\n",
       "      <td>A143</td>\n",
       "      <td>A153</td>\n",
       "      <td>1</td>\n",
       "      <td>A173</td>\n",
       "      <td>2</td>\n",
       "      <td>A191</td>\n",
       "      <td>A201</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4.0</td>\n",
       "      <td>A11</td>\n",
       "      <td>24</td>\n",
       "      <td>A33</td>\n",
       "      <td>A40</td>\n",
       "      <td>4870</td>\n",
       "      <td>A61</td>\n",
       "      <td>A73</td>\n",
       "      <td>3</td>\n",
       "      <td>A93</td>\n",
       "      <td>...</td>\n",
       "      <td>A124</td>\n",
       "      <td>53</td>\n",
       "      <td>A143</td>\n",
       "      <td>A153</td>\n",
       "      <td>2</td>\n",
       "      <td>A173</td>\n",
       "      <td>2</td>\n",
       "      <td>A191</td>\n",
       "      <td>A201</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>995.0</td>\n",
       "      <td>A14</td>\n",
       "      <td>12</td>\n",
       "      <td>A32</td>\n",
       "      <td>A42</td>\n",
       "      <td>1736</td>\n",
       "      <td>A61</td>\n",
       "      <td>A74</td>\n",
       "      <td>3</td>\n",
       "      <td>A92</td>\n",
       "      <td>...</td>\n",
       "      <td>A121</td>\n",
       "      <td>31</td>\n",
       "      <td>A143</td>\n",
       "      <td>A152</td>\n",
       "      <td>1</td>\n",
       "      <td>A172</td>\n",
       "      <td>1</td>\n",
       "      <td>A191</td>\n",
       "      <td>A201</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>996.0</td>\n",
       "      <td>A11</td>\n",
       "      <td>30</td>\n",
       "      <td>A32</td>\n",
       "      <td>A41</td>\n",
       "      <td>3857</td>\n",
       "      <td>A61</td>\n",
       "      <td>A73</td>\n",
       "      <td>4</td>\n",
       "      <td>A91</td>\n",
       "      <td>...</td>\n",
       "      <td>A122</td>\n",
       "      <td>40</td>\n",
       "      <td>A143</td>\n",
       "      <td>A152</td>\n",
       "      <td>1</td>\n",
       "      <td>A174</td>\n",
       "      <td>1</td>\n",
       "      <td>A192</td>\n",
       "      <td>A201</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>997.0</td>\n",
       "      <td>A14</td>\n",
       "      <td>12</td>\n",
       "      <td>A32</td>\n",
       "      <td>A43</td>\n",
       "      <td>804</td>\n",
       "      <td>A61</td>\n",
       "      <td>A75</td>\n",
       "      <td>4</td>\n",
       "      <td>A93</td>\n",
       "      <td>...</td>\n",
       "      <td>A123</td>\n",
       "      <td>38</td>\n",
       "      <td>A143</td>\n",
       "      <td>A152</td>\n",
       "      <td>1</td>\n",
       "      <td>A173</td>\n",
       "      <td>1</td>\n",
       "      <td>A191</td>\n",
       "      <td>A201</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>998.0</td>\n",
       "      <td>A11</td>\n",
       "      <td>45</td>\n",
       "      <td>A32</td>\n",
       "      <td>A43</td>\n",
       "      <td>1845</td>\n",
       "      <td>A61</td>\n",
       "      <td>A73</td>\n",
       "      <td>4</td>\n",
       "      <td>A93</td>\n",
       "      <td>...</td>\n",
       "      <td>A124</td>\n",
       "      <td>23</td>\n",
       "      <td>A143</td>\n",
       "      <td>A153</td>\n",
       "      <td>1</td>\n",
       "      <td>A173</td>\n",
       "      <td>1</td>\n",
       "      <td>A192</td>\n",
       "      <td>A201</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000</th>\n",
       "      <td>999.0</td>\n",
       "      <td>A12</td>\n",
       "      <td>45</td>\n",
       "      <td>A34</td>\n",
       "      <td>A41</td>\n",
       "      <td>4576</td>\n",
       "      <td>A62</td>\n",
       "      <td>A71</td>\n",
       "      <td>3</td>\n",
       "      <td>A93</td>\n",
       "      <td>...</td>\n",
       "      <td>A123</td>\n",
       "      <td>27</td>\n",
       "      <td>A143</td>\n",
       "      <td>A152</td>\n",
       "      <td>1</td>\n",
       "      <td>A173</td>\n",
       "      <td>1</td>\n",
       "      <td>A191</td>\n",
       "      <td>A201</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        NaN account_status duration credit_history purpose credit_amount  \\\n",
       "1       0.0            A11        6            A34     A43          1169   \n",
       "2       1.0            A12       48            A32     A43          5951   \n",
       "3       2.0            A14       12            A34     A46          2096   \n",
       "4       3.0            A11       42            A32     A42          7882   \n",
       "5       4.0            A11       24            A33     A40          4870   \n",
       "...     ...            ...      ...            ...     ...           ...   \n",
       "996   995.0            A14       12            A32     A42          1736   \n",
       "997   996.0            A11       30            A32     A41          3857   \n",
       "998   997.0            A14       12            A32     A43           804   \n",
       "999   998.0            A11       45            A32     A43          1845   \n",
       "1000  999.0            A12       45            A34     A41          4576   \n",
       "\n",
       "     savings_account unemployed installment_rate personal_status_sex  ...  \\\n",
       "1                A65        A75                4                 A93  ...   \n",
       "2                A61        A73                2                 A92  ...   \n",
       "3                A61        A74                2                 A93  ...   \n",
       "4                A61        A74                2                 A93  ...   \n",
       "5                A61        A73                3                 A93  ...   \n",
       "...              ...        ...              ...                 ...  ...   \n",
       "996              A61        A74                3                 A92  ...   \n",
       "997              A61        A73                4                 A91  ...   \n",
       "998              A61        A75                4                 A93  ...   \n",
       "999              A61        A73                4                 A93  ...   \n",
       "1000             A62        A71                3                 A93  ...   \n",
       "\n",
       "     property age other_installment_plans housing credits   job liable_for  \\\n",
       "1        A121  67                    A143    A152       2  A173          1   \n",
       "2        A121  22                    A143    A152       1  A173          1   \n",
       "3        A121  49                    A143    A152       1  A172          2   \n",
       "4        A122  45                    A143    A153       1  A173          2   \n",
       "5        A124  53                    A143    A153       2  A173          2   \n",
       "...       ...  ..                     ...     ...     ...   ...        ...   \n",
       "996      A121  31                    A143    A152       1  A172          1   \n",
       "997      A122  40                    A143    A152       1  A174          1   \n",
       "998      A123  38                    A143    A152       1  A173          1   \n",
       "999      A124  23                    A143    A153       1  A173          1   \n",
       "1000     A123  27                    A143    A152       1  A173          1   \n",
       "\n",
       "     telephone foreign_worker good/bad  \n",
       "1         A192           A201        1  \n",
       "2         A191           A201        2  \n",
       "3         A191           A201        1  \n",
       "4         A191           A201        1  \n",
       "5         A191           A201        2  \n",
       "...        ...            ...      ...  \n",
       "996       A191           A201        1  \n",
       "997       A192           A201        1  \n",
       "998       A191           A201        1  \n",
       "999       A192           A201        2  \n",
       "1000      A191           A201        1  \n",
       "\n",
       "[1000 rows x 22 columns]"
      ]
     },
     "execution_count": 264,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop NaN column\n",
    "data = data.iloc[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['account_status',\n",
       " 'duration',\n",
       " 'credit_history',\n",
       " 'purpose',\n",
       " 'credit_amount',\n",
       " 'savings_account',\n",
       " 'unemployed',\n",
       " 'installment_rate',\n",
       " 'personal_status_sex',\n",
       " 'debtors/guarantors',\n",
       " 'present_residence_since',\n",
       " 'property',\n",
       " 'age',\n",
       " 'other_installment_plans',\n",
       " 'housing',\n",
       " 'credits',\n",
       " 'job',\n",
       " 'liable_for',\n",
       " 'telephone',\n",
       " 'foreign_worker',\n",
       " 'good/bad']"
      ]
     },
     "execution_count": 266,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>account_status</th>\n",
       "      <th>duration</th>\n",
       "      <th>credit_history</th>\n",
       "      <th>purpose</th>\n",
       "      <th>credit_amount</th>\n",
       "      <th>savings_account</th>\n",
       "      <th>unemployed</th>\n",
       "      <th>installment_rate</th>\n",
       "      <th>debtors/guarantors</th>\n",
       "      <th>present_residence_since</th>\n",
       "      <th>property</th>\n",
       "      <th>age</th>\n",
       "      <th>other_installment_plans</th>\n",
       "      <th>housing</th>\n",
       "      <th>credits</th>\n",
       "      <th>job</th>\n",
       "      <th>good/bad</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A11</td>\n",
       "      <td>6</td>\n",
       "      <td>A34</td>\n",
       "      <td>A43</td>\n",
       "      <td>1169</td>\n",
       "      <td>A65</td>\n",
       "      <td>A75</td>\n",
       "      <td>4</td>\n",
       "      <td>A101</td>\n",
       "      <td>4</td>\n",
       "      <td>A121</td>\n",
       "      <td>67</td>\n",
       "      <td>A143</td>\n",
       "      <td>A152</td>\n",
       "      <td>2</td>\n",
       "      <td>A173</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A12</td>\n",
       "      <td>48</td>\n",
       "      <td>A32</td>\n",
       "      <td>A43</td>\n",
       "      <td>5951</td>\n",
       "      <td>A61</td>\n",
       "      <td>A73</td>\n",
       "      <td>2</td>\n",
       "      <td>A101</td>\n",
       "      <td>2</td>\n",
       "      <td>A121</td>\n",
       "      <td>22</td>\n",
       "      <td>A143</td>\n",
       "      <td>A152</td>\n",
       "      <td>1</td>\n",
       "      <td>A173</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A14</td>\n",
       "      <td>12</td>\n",
       "      <td>A34</td>\n",
       "      <td>A46</td>\n",
       "      <td>2096</td>\n",
       "      <td>A61</td>\n",
       "      <td>A74</td>\n",
       "      <td>2</td>\n",
       "      <td>A101</td>\n",
       "      <td>3</td>\n",
       "      <td>A121</td>\n",
       "      <td>49</td>\n",
       "      <td>A143</td>\n",
       "      <td>A152</td>\n",
       "      <td>1</td>\n",
       "      <td>A172</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A11</td>\n",
       "      <td>42</td>\n",
       "      <td>A32</td>\n",
       "      <td>A42</td>\n",
       "      <td>7882</td>\n",
       "      <td>A61</td>\n",
       "      <td>A74</td>\n",
       "      <td>2</td>\n",
       "      <td>A103</td>\n",
       "      <td>4</td>\n",
       "      <td>A122</td>\n",
       "      <td>45</td>\n",
       "      <td>A143</td>\n",
       "      <td>A153</td>\n",
       "      <td>1</td>\n",
       "      <td>A173</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>A11</td>\n",
       "      <td>24</td>\n",
       "      <td>A33</td>\n",
       "      <td>A40</td>\n",
       "      <td>4870</td>\n",
       "      <td>A61</td>\n",
       "      <td>A73</td>\n",
       "      <td>3</td>\n",
       "      <td>A101</td>\n",
       "      <td>4</td>\n",
       "      <td>A124</td>\n",
       "      <td>53</td>\n",
       "      <td>A143</td>\n",
       "      <td>A153</td>\n",
       "      <td>2</td>\n",
       "      <td>A173</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>A14</td>\n",
       "      <td>12</td>\n",
       "      <td>A32</td>\n",
       "      <td>A42</td>\n",
       "      <td>1736</td>\n",
       "      <td>A61</td>\n",
       "      <td>A74</td>\n",
       "      <td>3</td>\n",
       "      <td>A101</td>\n",
       "      <td>4</td>\n",
       "      <td>A121</td>\n",
       "      <td>31</td>\n",
       "      <td>A143</td>\n",
       "      <td>A152</td>\n",
       "      <td>1</td>\n",
       "      <td>A172</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>A11</td>\n",
       "      <td>30</td>\n",
       "      <td>A32</td>\n",
       "      <td>A41</td>\n",
       "      <td>3857</td>\n",
       "      <td>A61</td>\n",
       "      <td>A73</td>\n",
       "      <td>4</td>\n",
       "      <td>A101</td>\n",
       "      <td>4</td>\n",
       "      <td>A122</td>\n",
       "      <td>40</td>\n",
       "      <td>A143</td>\n",
       "      <td>A152</td>\n",
       "      <td>1</td>\n",
       "      <td>A174</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>A14</td>\n",
       "      <td>12</td>\n",
       "      <td>A32</td>\n",
       "      <td>A43</td>\n",
       "      <td>804</td>\n",
       "      <td>A61</td>\n",
       "      <td>A75</td>\n",
       "      <td>4</td>\n",
       "      <td>A101</td>\n",
       "      <td>4</td>\n",
       "      <td>A123</td>\n",
       "      <td>38</td>\n",
       "      <td>A143</td>\n",
       "      <td>A152</td>\n",
       "      <td>1</td>\n",
       "      <td>A173</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>A11</td>\n",
       "      <td>45</td>\n",
       "      <td>A32</td>\n",
       "      <td>A43</td>\n",
       "      <td>1845</td>\n",
       "      <td>A61</td>\n",
       "      <td>A73</td>\n",
       "      <td>4</td>\n",
       "      <td>A101</td>\n",
       "      <td>4</td>\n",
       "      <td>A124</td>\n",
       "      <td>23</td>\n",
       "      <td>A143</td>\n",
       "      <td>A153</td>\n",
       "      <td>1</td>\n",
       "      <td>A173</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000</th>\n",
       "      <td>A12</td>\n",
       "      <td>45</td>\n",
       "      <td>A34</td>\n",
       "      <td>A41</td>\n",
       "      <td>4576</td>\n",
       "      <td>A62</td>\n",
       "      <td>A71</td>\n",
       "      <td>3</td>\n",
       "      <td>A101</td>\n",
       "      <td>4</td>\n",
       "      <td>A123</td>\n",
       "      <td>27</td>\n",
       "      <td>A143</td>\n",
       "      <td>A152</td>\n",
       "      <td>1</td>\n",
       "      <td>A173</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     account_status duration credit_history purpose credit_amount  \\\n",
       "1               A11        6            A34     A43          1169   \n",
       "2               A12       48            A32     A43          5951   \n",
       "3               A14       12            A34     A46          2096   \n",
       "4               A11       42            A32     A42          7882   \n",
       "5               A11       24            A33     A40          4870   \n",
       "...             ...      ...            ...     ...           ...   \n",
       "996             A14       12            A32     A42          1736   \n",
       "997             A11       30            A32     A41          3857   \n",
       "998             A14       12            A32     A43           804   \n",
       "999             A11       45            A32     A43          1845   \n",
       "1000            A12       45            A34     A41          4576   \n",
       "\n",
       "     savings_account unemployed installment_rate debtors/guarantors  \\\n",
       "1                A65        A75                4               A101   \n",
       "2                A61        A73                2               A101   \n",
       "3                A61        A74                2               A101   \n",
       "4                A61        A74                2               A103   \n",
       "5                A61        A73                3               A101   \n",
       "...              ...        ...              ...                ...   \n",
       "996              A61        A74                3               A101   \n",
       "997              A61        A73                4               A101   \n",
       "998              A61        A75                4               A101   \n",
       "999              A61        A73                4               A101   \n",
       "1000             A62        A71                3               A101   \n",
       "\n",
       "     present_residence_since property age other_installment_plans housing  \\\n",
       "1                          4     A121  67                    A143    A152   \n",
       "2                          2     A121  22                    A143    A152   \n",
       "3                          3     A121  49                    A143    A152   \n",
       "4                          4     A122  45                    A143    A153   \n",
       "5                          4     A124  53                    A143    A153   \n",
       "...                      ...      ...  ..                     ...     ...   \n",
       "996                        4     A121  31                    A143    A152   \n",
       "997                        4     A122  40                    A143    A152   \n",
       "998                        4     A123  38                    A143    A152   \n",
       "999                        4     A124  23                    A143    A153   \n",
       "1000                       4     A123  27                    A143    A152   \n",
       "\n",
       "     credits   job good/bad  \n",
       "1          2  A173        1  \n",
       "2          1  A173        2  \n",
       "3          1  A172        1  \n",
       "4          1  A173        1  \n",
       "5          2  A173        2  \n",
       "...      ...   ...      ...  \n",
       "996        1  A172        1  \n",
       "997        1  A174        1  \n",
       "998        1  A173        1  \n",
       "999        1  A173        2  \n",
       "1000       1  A173        1  \n",
       "\n",
       "[1000 rows x 17 columns]"
      ]
     },
     "execution_count": 267,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop columns that should not impact risk \n",
    "data = data.drop(['foreign_worker', 'telephone', 'liable_for', 'personal_status_sex'], axis=1)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['account_status',\n",
       " 'credit_history',\n",
       " 'purpose',\n",
       " 'savings_account',\n",
       " 'unemployed',\n",
       " 'debtors/guarantors',\n",
       " 'property',\n",
       " 'other_installment_plans',\n",
       " 'housing',\n",
       " 'job']"
      ]
     },
     "execution_count": 268,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a_columns = ['account_status', 'credit_history', 'purpose', 'savings_account', 'unemployed', 'debtors/guarantors', 'property', 'other_installment_plans', 'housing', 'job']\n",
    "\n",
    "a_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[a_columns] = data[a_columns].replace({'A':''}, regex=True)\n",
    "data['good/bad'] = data['good/bad'].replace({'2':'0'}, regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>account_status</th>\n",
       "      <th>duration</th>\n",
       "      <th>credit_history</th>\n",
       "      <th>purpose</th>\n",
       "      <th>credit_amount</th>\n",
       "      <th>savings_account</th>\n",
       "      <th>unemployed</th>\n",
       "      <th>installment_rate</th>\n",
       "      <th>debtors/guarantors</th>\n",
       "      <th>present_residence_since</th>\n",
       "      <th>property</th>\n",
       "      <th>age</th>\n",
       "      <th>other_installment_plans</th>\n",
       "      <th>housing</th>\n",
       "      <th>credits</th>\n",
       "      <th>job</th>\n",
       "      <th>good/bad</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11</td>\n",
       "      <td>6</td>\n",
       "      <td>34</td>\n",
       "      <td>43</td>\n",
       "      <td>1169</td>\n",
       "      <td>65</td>\n",
       "      <td>75</td>\n",
       "      <td>4</td>\n",
       "      <td>101</td>\n",
       "      <td>4</td>\n",
       "      <td>121</td>\n",
       "      <td>67</td>\n",
       "      <td>143</td>\n",
       "      <td>152</td>\n",
       "      <td>2</td>\n",
       "      <td>173</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12</td>\n",
       "      <td>48</td>\n",
       "      <td>32</td>\n",
       "      <td>43</td>\n",
       "      <td>5951</td>\n",
       "      <td>61</td>\n",
       "      <td>73</td>\n",
       "      <td>2</td>\n",
       "      <td>101</td>\n",
       "      <td>2</td>\n",
       "      <td>121</td>\n",
       "      <td>22</td>\n",
       "      <td>143</td>\n",
       "      <td>152</td>\n",
       "      <td>1</td>\n",
       "      <td>173</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14</td>\n",
       "      <td>12</td>\n",
       "      <td>34</td>\n",
       "      <td>46</td>\n",
       "      <td>2096</td>\n",
       "      <td>61</td>\n",
       "      <td>74</td>\n",
       "      <td>2</td>\n",
       "      <td>101</td>\n",
       "      <td>3</td>\n",
       "      <td>121</td>\n",
       "      <td>49</td>\n",
       "      <td>143</td>\n",
       "      <td>152</td>\n",
       "      <td>1</td>\n",
       "      <td>172</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11</td>\n",
       "      <td>42</td>\n",
       "      <td>32</td>\n",
       "      <td>42</td>\n",
       "      <td>7882</td>\n",
       "      <td>61</td>\n",
       "      <td>74</td>\n",
       "      <td>2</td>\n",
       "      <td>103</td>\n",
       "      <td>4</td>\n",
       "      <td>122</td>\n",
       "      <td>45</td>\n",
       "      <td>143</td>\n",
       "      <td>153</td>\n",
       "      <td>1</td>\n",
       "      <td>173</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>11</td>\n",
       "      <td>24</td>\n",
       "      <td>33</td>\n",
       "      <td>40</td>\n",
       "      <td>4870</td>\n",
       "      <td>61</td>\n",
       "      <td>73</td>\n",
       "      <td>3</td>\n",
       "      <td>101</td>\n",
       "      <td>4</td>\n",
       "      <td>124</td>\n",
       "      <td>53</td>\n",
       "      <td>143</td>\n",
       "      <td>153</td>\n",
       "      <td>2</td>\n",
       "      <td>173</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>14</td>\n",
       "      <td>12</td>\n",
       "      <td>32</td>\n",
       "      <td>42</td>\n",
       "      <td>1736</td>\n",
       "      <td>61</td>\n",
       "      <td>74</td>\n",
       "      <td>3</td>\n",
       "      <td>101</td>\n",
       "      <td>4</td>\n",
       "      <td>121</td>\n",
       "      <td>31</td>\n",
       "      <td>143</td>\n",
       "      <td>152</td>\n",
       "      <td>1</td>\n",
       "      <td>172</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>11</td>\n",
       "      <td>30</td>\n",
       "      <td>32</td>\n",
       "      <td>41</td>\n",
       "      <td>3857</td>\n",
       "      <td>61</td>\n",
       "      <td>73</td>\n",
       "      <td>4</td>\n",
       "      <td>101</td>\n",
       "      <td>4</td>\n",
       "      <td>122</td>\n",
       "      <td>40</td>\n",
       "      <td>143</td>\n",
       "      <td>152</td>\n",
       "      <td>1</td>\n",
       "      <td>174</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>14</td>\n",
       "      <td>12</td>\n",
       "      <td>32</td>\n",
       "      <td>43</td>\n",
       "      <td>804</td>\n",
       "      <td>61</td>\n",
       "      <td>75</td>\n",
       "      <td>4</td>\n",
       "      <td>101</td>\n",
       "      <td>4</td>\n",
       "      <td>123</td>\n",
       "      <td>38</td>\n",
       "      <td>143</td>\n",
       "      <td>152</td>\n",
       "      <td>1</td>\n",
       "      <td>173</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>11</td>\n",
       "      <td>45</td>\n",
       "      <td>32</td>\n",
       "      <td>43</td>\n",
       "      <td>1845</td>\n",
       "      <td>61</td>\n",
       "      <td>73</td>\n",
       "      <td>4</td>\n",
       "      <td>101</td>\n",
       "      <td>4</td>\n",
       "      <td>124</td>\n",
       "      <td>23</td>\n",
       "      <td>143</td>\n",
       "      <td>153</td>\n",
       "      <td>1</td>\n",
       "      <td>173</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000</th>\n",
       "      <td>12</td>\n",
       "      <td>45</td>\n",
       "      <td>34</td>\n",
       "      <td>41</td>\n",
       "      <td>4576</td>\n",
       "      <td>62</td>\n",
       "      <td>71</td>\n",
       "      <td>3</td>\n",
       "      <td>101</td>\n",
       "      <td>4</td>\n",
       "      <td>123</td>\n",
       "      <td>27</td>\n",
       "      <td>143</td>\n",
       "      <td>152</td>\n",
       "      <td>1</td>\n",
       "      <td>173</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      account_status  duration  credit_history  purpose  credit_amount  \\\n",
       "1                 11         6              34       43           1169   \n",
       "2                 12        48              32       43           5951   \n",
       "3                 14        12              34       46           2096   \n",
       "4                 11        42              32       42           7882   \n",
       "5                 11        24              33       40           4870   \n",
       "...              ...       ...             ...      ...            ...   \n",
       "996               14        12              32       42           1736   \n",
       "997               11        30              32       41           3857   \n",
       "998               14        12              32       43            804   \n",
       "999               11        45              32       43           1845   \n",
       "1000              12        45              34       41           4576   \n",
       "\n",
       "      savings_account  unemployed  installment_rate  debtors/guarantors  \\\n",
       "1                  65          75                 4                 101   \n",
       "2                  61          73                 2                 101   \n",
       "3                  61          74                 2                 101   \n",
       "4                  61          74                 2                 103   \n",
       "5                  61          73                 3                 101   \n",
       "...               ...         ...               ...                 ...   \n",
       "996                61          74                 3                 101   \n",
       "997                61          73                 4                 101   \n",
       "998                61          75                 4                 101   \n",
       "999                61          73                 4                 101   \n",
       "1000               62          71                 3                 101   \n",
       "\n",
       "      present_residence_since  property  age  other_installment_plans  \\\n",
       "1                           4       121   67                      143   \n",
       "2                           2       121   22                      143   \n",
       "3                           3       121   49                      143   \n",
       "4                           4       122   45                      143   \n",
       "5                           4       124   53                      143   \n",
       "...                       ...       ...  ...                      ...   \n",
       "996                         4       121   31                      143   \n",
       "997                         4       122   40                      143   \n",
       "998                         4       123   38                      143   \n",
       "999                         4       124   23                      143   \n",
       "1000                        4       123   27                      143   \n",
       "\n",
       "      housing  credits  job  good/bad  \n",
       "1         152        2  173         1  \n",
       "2         152        1  173         0  \n",
       "3         152        1  172         1  \n",
       "4         153        1  173         1  \n",
       "5         153        2  173         0  \n",
       "...       ...      ...  ...       ...  \n",
       "996       152        1  172         1  \n",
       "997       152        1  174         1  \n",
       "998       152        1  173         1  \n",
       "999       153        1  173         0  \n",
       "1000      152        1  173         1  \n",
       "\n",
       "[1000 rows x 17 columns]"
      ]
     },
     "execution_count": 270,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data.apply(pd.to_numeric) \n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_data = [\"account_status\", \"credit_history\", \"purpose\", \"savings_account\", \"unemployed\", \"debtors/guarantors\", \"property\", \"other_installment_plans\", \"housing\", \"job\"]\n",
    "dummy_data = pd.get_dummies(data, columns=categorical_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv('german.csv')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define X and y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign X (data) and y (target)\n",
    "X = dummy_data.drop(\"good/bad\", axis=1)\n",
    "y = dummy_data[\"good/bad\"]\n",
    "#print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 52) (1000,)\n"
     ]
    }
   ],
   "source": [
    "#Assign X and Y using dummy encoded data\n",
    "# Assign X (data) and y (target)\n",
    "#X = dummy_data.drop(\"good/bad\", axis=1)\n",
    "#y = dummy_data[\"good/bad\"]\n",
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split our data into training and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import RandomOverSampler\n",
    "ros = RandomOverSampler(random_state=1)\n",
    "X_resampled, y_resampled = ros.fit_resample(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    527\n",
       "1    523\n",
       "Name: good/bad, dtype: int64"
      ]
     },
     "execution_count": 277,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scale Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "X_train_minmax = min_max_scaler.fit_transform(X_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_minmax = min_max_scaler.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a Logistic Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 280,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "classifier = LogisticRegression()\n",
    "classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 281,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.fit(X_train_minmax, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data Score: 0.7676190476190476\n",
      "Testing Data Score: 0.7371428571428571\n"
     ]
    }
   ],
   "source": [
    "print(f\"Training Data Score: {classifier.score(X_train_minmax, y_train)}\")\n",
    "print(f\"Testing Data Score: {classifier.score(X_test_minmax, y_test)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fit (train) or model using the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 10 Predictions:   [1 1 0 0 0 0 0 1 0 0]\n",
      "First 10 Actual labels: [1, 0, 0, 0, 0, 0, 0, 1, 0, 1]\n"
     ]
    }
   ],
   "source": [
    "classifier_predictions = classifier.predict(X_test_minmax)\n",
    "print(f\"First 10 Predictions:   {classifier_predictions[:10]}\")\n",
    "print(f\"First 10 Actual labels: {y_test[:10].tolist()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validate the model using the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bad       0.72      0.76      0.74       173\n",
      "        good       0.75      0.72      0.73       177\n",
      "\n",
      "    accuracy                           0.74       350\n",
      "   macro avg       0.74      0.74      0.74       350\n",
      "weighted avg       0.74      0.74      0.74       350\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print (classification_report(y_test, classifier_predictions,\n",
    "                            target_names=[\"bad\",\"good\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Prediction</th>\n",
       "      <th>Actual</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>345</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>346</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>347</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>348</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>349</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>350 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Prediction  Actual\n",
       "0             1       1\n",
       "1             1       0\n",
       "2             0       0\n",
       "3             0       0\n",
       "4             0       0\n",
       "..          ...     ...\n",
       "345           1       1\n",
       "346           1       1\n",
       "347           0       1\n",
       "348           1       1\n",
       "349           0       1\n",
       "\n",
       "[350 rows x 2 columns]"
      ]
     },
     "execution_count": 286,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame({\"Prediction\": classifier_predictions, \"Actual\": y_test}).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.47955718, -1.54014023, -0.88146005, -0.07793396,  1.02080088,\n",
       "        -0.57796503, -0.81322059, -0.41467202,  0.22437589,  1.00496878,\n",
       "        -0.48243332, -0.574644  , -0.08973504,  0.20689408,  0.94137035,\n",
       "        -0.71293727,  0.62801763, -0.15413028,  0.16626536, -0.16822147,\n",
       "        -0.30584076, -0.55888097,  0.61381954, -0.18786431,  0.68122458,\n",
       "        -0.64452164, -0.32759329,  0.08075607,  0.7345216 ,  0.15828933,\n",
       "        -0.16415103, -0.43911462, -0.10597715,  0.57254514,  0.13814973,\n",
       "        -0.16468056, -0.66637859,  0.83251122,  0.19992292, -0.12457018,\n",
       "         0.06722077, -0.14112144, -0.27301065, -0.00180606,  0.27626878,\n",
       "        -0.04882482,  0.1604041 , -0.11012722,  0.61045511, -0.10074489,\n",
       "        -0.14710784, -0.36115031]])"
      ]
     },
     "execution_count": 287,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimize with Gridsearch model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create the GridSearch estimator along with a parameter object containing the values to adjust\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "param_grid = {'C': [.01, .1, 1, 2],\n",
    "              'penalty': ['l1', 'l2', 'elasticnet', 'none'],\n",
    "             'solver': ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga']}\n",
    "grid = GridSearchCV(classifier, param_grid, verbose=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 80 candidates, totalling 400 fits\n",
      "[CV] C=0.01, penalty=l1, solver=newton-cg ............................\n",
      "[CV] .. C=0.01, penalty=l1, solver=newton-cg, score=nan, total=   0.0s\n",
      "[CV] C=0.01, penalty=l1, solver=newton-cg ............................\n",
      "[CV] .. C=0.01, penalty=l1, solver=newton-cg, score=nan, total=   0.0s\n",
      "[CV] C=0.01, penalty=l1, solver=newton-cg ............................\n",
      "[CV] .. C=0.01, penalty=l1, solver=newton-cg, score=nan, total=   0.0s\n",
      "[CV] C=0.01, penalty=l1, solver=newton-cg ............................\n",
      "[CV] .. C=0.01, penalty=l1, solver=newton-cg, score=nan, total=   0.0s\n",
      "[CV] C=0.01, penalty=l1, solver=newton-cg ............................\n",
      "[CV] .. C=0.01, penalty=l1, solver=newton-cg, score=nan, total=   0.0s\n",
      "[CV] C=0.01, penalty=l1, solver=lbfgs ................................\n",
      "[CV] ...... C=0.01, penalty=l1, solver=lbfgs, score=nan, total=   0.0s\n",
      "[CV] C=0.01, penalty=l1, solver=lbfgs ................................\n",
      "[CV] ...... C=0.01, penalty=l1, solver=lbfgs, score=nan, total=   0.0s\n",
      "[CV] C=0.01, penalty=l1, solver=lbfgs ................................\n",
      "[CV] ...... C=0.01, penalty=l1, solver=lbfgs, score=nan, total=   0.0s\n",
      "[CV] C=0.01, penalty=l1, solver=lbfgs ................................\n",
      "[CV] ...... C=0.01, penalty=l1, solver=lbfgs, score=nan, total=   0.0s\n",
      "[CV] C=0.01, penalty=l1, solver=lbfgs ................................\n",
      "[CV] ...... C=0.01, penalty=l1, solver=lbfgs, score=nan, total=   0.0s\n",
      "[CV] C=0.01, penalty=l1, solver=liblinear ............................\n",
      "[CV]  C=0.01, penalty=l1, solver=liblinear, score=0.505, total=   0.0s\n",
      "[CV] C=0.01, penalty=l1, solver=liblinear ............................\n",
      "[CV]  C=0.01, penalty=l1, solver=liblinear, score=0.505, total=   0.0s\n",
      "[CV] C=0.01, penalty=l1, solver=liblinear ............................\n",
      "[CV]  C=0.01, penalty=l1, solver=liblinear, score=0.500, total=   0.0s\n",
      "[CV] C=0.01, penalty=l1, solver=liblinear ............................\n",
      "[CV]  C=0.01, penalty=l1, solver=liblinear, score=0.500, total=   0.0s\n",
      "[CV] C=0.01, penalty=l1, solver=liblinear ............................\n",
      "[CV]  C=0.01, penalty=l1, solver=liblinear, score=0.500, total=   0.0s\n",
      "[CV] C=0.01, penalty=l1, solver=sag ..................................\n",
      "[CV] ........ C=0.01, penalty=l1, solver=sag, score=nan, total=   0.0s\n",
      "[CV] C=0.01, penalty=l1, solver=sag ..................................\n",
      "[CV] ........ C=0.01, penalty=l1, solver=sag, score=nan, total=   0.0s\n",
      "[CV] C=0.01, penalty=l1, solver=sag ..................................\n",
      "[CV] ........ C=0.01, penalty=l1, solver=sag, score=nan, total=   0.0s\n",
      "[CV] C=0.01, penalty=l1, solver=sag ..................................\n",
      "[CV] ........ C=0.01, penalty=l1, solver=sag, score=nan, total=   0.0s\n",
      "[CV] C=0.01, penalty=l1, solver=sag ..................................\n",
      "[CV] ........ C=0.01, penalty=l1, solver=sag, score=nan, total=   0.0s\n",
      "[CV] C=0.01, penalty=l1, solver=saga .................................\n",
      "[CV] ..... C=0.01, penalty=l1, solver=saga, score=0.505, total=   0.0s\n",
      "[CV] C=0.01, penalty=l1, solver=saga .................................\n",
      "[CV] ..... C=0.01, penalty=l1, solver=saga, score=0.495, total=   0.0s\n",
      "[CV] C=0.01, penalty=l1, solver=saga .................................\n",
      "[CV] ..... C=0.01, penalty=l1, solver=saga, score=0.500, total=   0.0s\n",
      "[CV] C=0.01, penalty=l1, solver=saga .................................\n",
      "[CV] ..... C=0.01, penalty=l1, solver=saga, score=0.500, total=   0.0s\n",
      "[CV] C=0.01, penalty=l1, solver=saga .................................\n",
      "[CV] ..... C=0.01, penalty=l1, solver=saga, score=0.500, total=   0.0s\n",
      "[CV] C=0.01, penalty=l2, solver=newton-cg ............................\n",
      "[CV]  C=0.01, penalty=l2, solver=newton-cg, score=0.705, total=   0.0s\n",
      "[CV] C=0.01, penalty=l2, solver=newton-cg ............................\n",
      "[CV]  C=0.01, penalty=l2, solver=newton-cg, score=0.729, total=   0.0s\n",
      "[CV] C=0.01, penalty=l2, solver=newton-cg ............................\n",
      "[CV]  C=0.01, penalty=l2, solver=newton-cg, score=0.724, total=   0.0s\n",
      "[CV] C=0.01, penalty=l2, solver=newton-cg ............................\n",
      "[CV]  C=0.01, penalty=l2, solver=newton-cg, score=0.810, total=   0.0s\n",
      "[CV] C=0.01, penalty=l2, solver=newton-cg ............................\n",
      "[CV]  C=0.01, penalty=l2, solver=newton-cg, score=0.714, total=   0.0s\n",
      "[CV] C=0.01, penalty=l2, solver=lbfgs ................................\n",
      "[CV] .... C=0.01, penalty=l2, solver=lbfgs, score=0.705, total=   0.0s\n",
      "[CV] C=0.01, penalty=l2, solver=lbfgs ................................\n",
      "[CV] .... C=0.01, penalty=l2, solver=lbfgs, score=0.729, total=   0.0s\n",
      "[CV] C=0.01, penalty=l2, solver=lbfgs ................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "/Users/tajahneiwilliams/opt/anaconda3/envs/PythonAdv/lib/python3.6/site-packages/sklearn/model_selection/_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/tajahneiwilliams/opt/anaconda3/envs/PythonAdv/lib/python3.6/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/tajahneiwilliams/opt/anaconda3/envs/PythonAdv/lib/python3.6/site-packages/sklearn/linear_model/_logistic.py\", line 1304, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/Users/tajahneiwilliams/opt/anaconda3/envs/PythonAdv/lib/python3.6/site-packages/sklearn/linear_model/_logistic.py\", line 443, in _check_solver\n",
      "    \"got %s penalty.\" % (solver, penalty))\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  FitFailedWarning)\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "/Users/tajahneiwilliams/opt/anaconda3/envs/PythonAdv/lib/python3.6/site-packages/sklearn/model_selection/_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/tajahneiwilliams/opt/anaconda3/envs/PythonAdv/lib/python3.6/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/tajahneiwilliams/opt/anaconda3/envs/PythonAdv/lib/python3.6/site-packages/sklearn/linear_model/_logistic.py\", line 1304, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/Users/tajahneiwilliams/opt/anaconda3/envs/PythonAdv/lib/python3.6/site-packages/sklearn/linear_model/_logistic.py\", line 443, in _check_solver\n",
      "    \"got %s penalty.\" % (solver, penalty))\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/tajahneiwilliams/opt/anaconda3/envs/PythonAdv/lib/python3.6/site-packages/sklearn/model_selection/_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/tajahneiwilliams/opt/anaconda3/envs/PythonAdv/lib/python3.6/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/tajahneiwilliams/opt/anaconda3/envs/PythonAdv/lib/python3.6/site-packages/sklearn/linear_model/_logistic.py\", line 1304, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/Users/tajahneiwilliams/opt/anaconda3/envs/PythonAdv/lib/python3.6/site-packages/sklearn/linear_model/_logistic.py\", line 443, in _check_solver\n",
      "    \"got %s penalty.\" % (solver, penalty))\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .... C=0.01, penalty=l2, solver=lbfgs, score=0.724, total=   0.0s\n",
      "[CV] C=0.01, penalty=l2, solver=lbfgs ................................\n",
      "[CV] .... C=0.01, penalty=l2, solver=lbfgs, score=0.810, total=   0.0s\n",
      "[CV] C=0.01, penalty=l2, solver=lbfgs ................................\n",
      "[CV] .... C=0.01, penalty=l2, solver=lbfgs, score=0.714, total=   0.0s\n",
      "[CV] C=0.01, penalty=l2, solver=liblinear ............................\n",
      "[CV]  C=0.01, penalty=l2, solver=liblinear, score=0.705, total=   0.0s\n",
      "[CV] C=0.01, penalty=l2, solver=liblinear ............................\n",
      "[CV]  C=0.01, penalty=l2, solver=liblinear, score=0.724, total=   0.0s\n",
      "[CV] C=0.01, penalty=l2, solver=liblinear ............................\n",
      "[CV]  C=0.01, penalty=l2, solver=liblinear, score=0.733, total=   0.0s\n",
      "[CV] C=0.01, penalty=l2, solver=liblinear ............................\n",
      "[CV]  C=0.01, penalty=l2, solver=liblinear, score=0.795, total=   0.0s\n",
      "[CV] C=0.01, penalty=l2, solver=liblinear ............................\n",
      "[CV]  C=0.01, penalty=l2, solver=liblinear, score=0.714, total=   0.0s\n",
      "[CV] C=0.01, penalty=l2, solver=sag ..................................\n",
      "[CV] ...... C=0.01, penalty=l2, solver=sag, score=0.705, total=   0.0s\n",
      "[CV] C=0.01, penalty=l2, solver=sag ..................................\n",
      "[CV] ...... C=0.01, penalty=l2, solver=sag, score=0.729, total=   0.0s\n",
      "[CV] C=0.01, penalty=l2, solver=sag ..................................\n",
      "[CV] ...... C=0.01, penalty=l2, solver=sag, score=0.724, total=   0.0s\n",
      "[CV] C=0.01, penalty=l2, solver=sag ..................................\n",
      "[CV] ...... C=0.01, penalty=l2, solver=sag, score=0.810, total=   0.0s\n",
      "[CV] C=0.01, penalty=l2, solver=sag ..................................\n",
      "[CV] ...... C=0.01, penalty=l2, solver=sag, score=0.714, total=   0.0s\n",
      "[CV] C=0.01, penalty=l2, solver=saga .................................\n",
      "[CV] ..... C=0.01, penalty=l2, solver=saga, score=0.705, total=   0.0s\n",
      "[CV] C=0.01, penalty=l2, solver=saga .................................\n",
      "[CV] ..... C=0.01, penalty=l2, solver=saga, score=0.729, total=   0.0s\n",
      "[CV] C=0.01, penalty=l2, solver=saga .................................\n",
      "[CV] ..... C=0.01, penalty=l2, solver=saga, score=0.724, total=   0.0s\n",
      "[CV] C=0.01, penalty=l2, solver=saga .................................\n",
      "[CV] ..... C=0.01, penalty=l2, solver=saga, score=0.810, total=   0.0s\n",
      "[CV] C=0.01, penalty=l2, solver=saga .................................\n",
      "[CV] ..... C=0.01, penalty=l2, solver=saga, score=0.714, total=   0.0s\n",
      "[CV] C=0.01, penalty=elasticnet, solver=newton-cg ....................\n",
      "[CV]  C=0.01, penalty=elasticnet, solver=newton-cg, score=nan, total=   0.0s\n",
      "[CV] C=0.01, penalty=elasticnet, solver=newton-cg ....................\n",
      "[CV]  C=0.01, penalty=elasticnet, solver=newton-cg, score=nan, total=   0.0s\n",
      "[CV] C=0.01, penalty=elasticnet, solver=newton-cg ....................\n",
      "[CV]  C=0.01, penalty=elasticnet, solver=newton-cg, score=nan, total=   0.0s\n",
      "[CV] C=0.01, penalty=elasticnet, solver=newton-cg ....................\n",
      "[CV]  C=0.01, penalty=elasticnet, solver=newton-cg, score=nan, total=   0.0s\n",
      "[CV] C=0.01, penalty=elasticnet, solver=newton-cg ....................\n",
      "[CV]  C=0.01, penalty=elasticnet, solver=newton-cg, score=nan, total=   0.0s\n",
      "[CV] C=0.01, penalty=elasticnet, solver=lbfgs ........................\n",
      "[CV]  C=0.01, penalty=elasticnet, solver=lbfgs, score=nan, total=   0.0s\n",
      "[CV] C=0.01, penalty=elasticnet, solver=lbfgs ........................\n",
      "[CV]  C=0.01, penalty=elasticnet, solver=lbfgs, score=nan, total=   0.0s\n",
      "[CV] C=0.01, penalty=elasticnet, solver=lbfgs ........................\n",
      "[CV]  C=0.01, penalty=elasticnet, solver=lbfgs, score=nan, total=   0.0s\n",
      "[CV] C=0.01, penalty=elasticnet, solver=lbfgs ........................\n",
      "[CV]  C=0.01, penalty=elasticnet, solver=lbfgs, score=nan, total=   0.0s\n",
      "[CV] C=0.01, penalty=elasticnet, solver=lbfgs ........................\n",
      "[CV]  C=0.01, penalty=elasticnet, solver=lbfgs, score=nan, total=   0.0s\n",
      "[CV] C=0.01, penalty=elasticnet, solver=liblinear ....................\n",
      "[CV]  C=0.01, penalty=elasticnet, solver=liblinear, score=nan, total=   0.0s\n",
      "[CV] C=0.01, penalty=elasticnet, solver=liblinear ....................\n",
      "[CV]  C=0.01, penalty=elasticnet, solver=liblinear, score=nan, total=   0.0s\n",
      "[CV] C=0.01, penalty=elasticnet, solver=liblinear ....................\n",
      "[CV]  C=0.01, penalty=elasticnet, solver=liblinear, score=nan, total=   0.0s\n",
      "[CV] C=0.01, penalty=elasticnet, solver=liblinear ....................\n",
      "[CV]  C=0.01, penalty=elasticnet, solver=liblinear, score=nan, total=   0.0s\n",
      "[CV] C=0.01, penalty=elasticnet, solver=liblinear ....................\n",
      "[CV]  C=0.01, penalty=elasticnet, solver=liblinear, score=nan, total=   0.0s\n",
      "[CV] C=0.01, penalty=elasticnet, solver=sag ..........................\n",
      "[CV]  C=0.01, penalty=elasticnet, solver=sag, score=nan, total=   0.0s\n",
      "[CV] C=0.01, penalty=elasticnet, solver=sag ..........................\n",
      "[CV]  C=0.01, penalty=elasticnet, solver=sag, score=nan, total=   0.0s\n",
      "[CV] C=0.01, penalty=elasticnet, solver=sag ..........................\n",
      "[CV]  C=0.01, penalty=elasticnet, solver=sag, score=nan, total=   0.0s\n",
      "[CV] C=0.01, penalty=elasticnet, solver=sag ..........................\n",
      "[CV]  C=0.01, penalty=elasticnet, solver=sag, score=nan, total=   0.0s\n",
      "[CV] C=0.01, penalty=elasticnet, solver=sag ..........................\n",
      "[CV]  C=0.01, penalty=elasticnet, solver=sag, score=nan, total=   0.0s\n",
      "[CV] C=0.01, penalty=elasticnet, solver=saga .........................\n",
      "[CV]  C=0.01, penalty=elasticnet, solver=saga, score=nan, total=   0.0s\n",
      "[CV] C=0.01, penalty=elasticnet, solver=saga .........................\n",
      "[CV]  C=0.01, penalty=elasticnet, solver=saga, score=nan, total=   0.0s\n",
      "[CV] C=0.01, penalty=elasticnet, solver=saga .........................\n",
      "[CV]  C=0.01, penalty=elasticnet, solver=saga, score=nan, total=   0.0s\n",
      "[CV] C=0.01, penalty=elasticnet, solver=saga .........................\n",
      "[CV]  C=0.01, penalty=elasticnet, solver=saga, score=nan, total=   0.0s\n",
      "[CV] C=0.01, penalty=elasticnet, solver=saga .........................\n",
      "[CV]  C=0.01, penalty=elasticnet, solver=saga, score=nan, total=   0.0s\n",
      "[CV] C=0.01, penalty=none, solver=newton-cg ..........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tajahneiwilliams/opt/anaconda3/envs/PythonAdv/lib/python3.6/site-packages/sklearn/model_selection/_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/tajahneiwilliams/opt/anaconda3/envs/PythonAdv/lib/python3.6/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/tajahneiwilliams/opt/anaconda3/envs/PythonAdv/lib/python3.6/site-packages/sklearn/linear_model/_logistic.py\", line 1304, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/Users/tajahneiwilliams/opt/anaconda3/envs/PythonAdv/lib/python3.6/site-packages/sklearn/linear_model/_logistic.py\", line 443, in _check_solver\n",
      "    \"got %s penalty.\" % (solver, penalty))\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/tajahneiwilliams/opt/anaconda3/envs/PythonAdv/lib/python3.6/site-packages/sklearn/model_selection/_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/tajahneiwilliams/opt/anaconda3/envs/PythonAdv/lib/python3.6/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/tajahneiwilliams/opt/anaconda3/envs/PythonAdv/lib/python3.6/site-packages/sklearn/linear_model/_logistic.py\", line 1304, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/Users/tajahneiwilliams/opt/anaconda3/envs/PythonAdv/lib/python3.6/site-packages/sklearn/linear_model/_logistic.py\", line 443, in _check_solver\n",
      "    \"got %s penalty.\" % (solver, penalty))\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/tajahneiwilliams/opt/anaconda3/envs/PythonAdv/lib/python3.6/site-packages/sklearn/model_selection/_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/tajahneiwilliams/opt/anaconda3/envs/PythonAdv/lib/python3.6/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/tajahneiwilliams/opt/anaconda3/envs/PythonAdv/lib/python3.6/site-packages/sklearn/linear_model/_logistic.py\", line 1304, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/Users/tajahneiwilliams/opt/anaconda3/envs/PythonAdv/lib/python3.6/site-packages/sklearn/linear_model/_logistic.py\", line 450, in _check_solver\n",
      "    \" got solver={}.\".format(solver))\n",
      "ValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/tajahneiwilliams/opt/anaconda3/envs/PythonAdv/lib/python3.6/site-packages/sklearn/model_selection/_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/tajahneiwilliams/opt/anaconda3/envs/PythonAdv/lib/python3.6/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/tajahneiwilliams/opt/anaconda3/envs/PythonAdv/lib/python3.6/site-packages/sklearn/linear_model/_logistic.py\", line 1304, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/Users/tajahneiwilliams/opt/anaconda3/envs/PythonAdv/lib/python3.6/site-packages/sklearn/linear_model/_logistic.py\", line 443, in _check_solver\n",
      "    \"got %s penalty.\" % (solver, penalty))\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/tajahneiwilliams/opt/anaconda3/envs/PythonAdv/lib/python3.6/site-packages/sklearn/model_selection/_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/tajahneiwilliams/opt/anaconda3/envs/PythonAdv/lib/python3.6/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/tajahneiwilliams/opt/anaconda3/envs/PythonAdv/lib/python3.6/site-packages/sklearn/linear_model/_logistic.py\", line 1313, in fit\n",
      "    \" got (l1_ratio=%r)\" % self.l1_ratio)\n",
      "ValueError: l1_ratio must be between 0 and 1; got (l1_ratio=None)\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/tajahneiwilliams/opt/anaconda3/envs/PythonAdv/lib/python3.6/site-packages/sklearn/linear_model/_logistic.py:1321: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "/Users/tajahneiwilliams/opt/anaconda3/envs/PythonAdv/lib/python3.6/site-packages/sklearn/linear_model/_logistic.py:1321: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "/Users/tajahneiwilliams/opt/anaconda3/envs/PythonAdv/lib/python3.6/site-packages/sklearn/linear_model/_logistic.py:1321: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "/Users/tajahneiwilliams/opt/anaconda3/envs/PythonAdv/lib/python3.6/site-packages/sklearn/linear_model/_logistic.py:1321: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "/Users/tajahneiwilliams/opt/anaconda3/envs/PythonAdv/lib/python3.6/site-packages/sklearn/linear_model/_logistic.py:1321: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "/Users/tajahneiwilliams/opt/anaconda3/envs/PythonAdv/lib/python3.6/site-packages/sklearn/linear_model/_logistic.py:1321: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "/Users/tajahneiwilliams/opt/anaconda3/envs/PythonAdv/lib/python3.6/site-packages/sklearn/linear_model/_logistic.py:1321: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "/Users/tajahneiwilliams/opt/anaconda3/envs/PythonAdv/lib/python3.6/site-packages/sklearn/linear_model/_logistic.py:1321: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "/Users/tajahneiwilliams/opt/anaconda3/envs/PythonAdv/lib/python3.6/site-packages/sklearn/linear_model/_logistic.py:1321: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "/Users/tajahneiwilliams/opt/anaconda3/envs/PythonAdv/lib/python3.6/site-packages/sklearn/linear_model/_logistic.py:1321: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  C=0.01, penalty=none, solver=newton-cg, score=0.719, total=   0.0s\n",
      "[CV] C=0.01, penalty=none, solver=newton-cg ..........................\n",
      "[CV]  C=0.01, penalty=none, solver=newton-cg, score=0.767, total=   0.0s\n",
      "[CV] C=0.01, penalty=none, solver=newton-cg ..........................\n",
      "[CV]  C=0.01, penalty=none, solver=newton-cg, score=0.729, total=   0.0s\n",
      "[CV] C=0.01, penalty=none, solver=newton-cg ..........................\n",
      "[CV]  C=0.01, penalty=none, solver=newton-cg, score=0.752, total=   0.0s\n",
      "[CV] C=0.01, penalty=none, solver=newton-cg ..........................\n",
      "[CV]  C=0.01, penalty=none, solver=newton-cg, score=0.733, total=   0.0s\n",
      "[CV] C=0.01, penalty=none, solver=lbfgs ..............................\n",
      "[CV] .. C=0.01, penalty=none, solver=lbfgs, score=0.719, total=   0.0s\n",
      "[CV] C=0.01, penalty=none, solver=lbfgs ..............................\n",
      "[CV] .. C=0.01, penalty=none, solver=lbfgs, score=0.767, total=   0.0s\n",
      "[CV] C=0.01, penalty=none, solver=lbfgs ..............................\n",
      "[CV] .. C=0.01, penalty=none, solver=lbfgs, score=0.729, total=   0.0s\n",
      "[CV] C=0.01, penalty=none, solver=lbfgs ..............................\n",
      "[CV] .. C=0.01, penalty=none, solver=lbfgs, score=0.752, total=   0.0s\n",
      "[CV] C=0.01, penalty=none, solver=lbfgs ..............................\n",
      "[CV] .. C=0.01, penalty=none, solver=lbfgs, score=0.733, total=   0.0s\n",
      "[CV] C=0.01, penalty=none, solver=liblinear ..........................\n",
      "[CV]  C=0.01, penalty=none, solver=liblinear, score=nan, total=   0.0s\n",
      "[CV] C=0.01, penalty=none, solver=liblinear ..........................\n",
      "[CV]  C=0.01, penalty=none, solver=liblinear, score=nan, total=   0.0s\n",
      "[CV] C=0.01, penalty=none, solver=liblinear ..........................\n",
      "[CV]  C=0.01, penalty=none, solver=liblinear, score=nan, total=   0.0s\n",
      "[CV] C=0.01, penalty=none, solver=liblinear ..........................\n",
      "[CV]  C=0.01, penalty=none, solver=liblinear, score=nan, total=   0.0s\n",
      "[CV] C=0.01, penalty=none, solver=liblinear ..........................\n",
      "[CV]  C=0.01, penalty=none, solver=liblinear, score=nan, total=   0.0s\n",
      "[CV] C=0.01, penalty=none, solver=sag ................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tajahneiwilliams/opt/anaconda3/envs/PythonAdv/lib/python3.6/site-packages/sklearn/model_selection/_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/tajahneiwilliams/opt/anaconda3/envs/PythonAdv/lib/python3.6/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/tajahneiwilliams/opt/anaconda3/envs/PythonAdv/lib/python3.6/site-packages/sklearn/linear_model/_logistic.py\", line 1304, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/Users/tajahneiwilliams/opt/anaconda3/envs/PythonAdv/lib/python3.6/site-packages/sklearn/linear_model/_logistic.py\", line 454, in _check_solver\n",
      "    \"penalty='none' is not supported for the liblinear solver\"\n",
      "ValueError: penalty='none' is not supported for the liblinear solver\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/tajahneiwilliams/opt/anaconda3/envs/PythonAdv/lib/python3.6/site-packages/sklearn/linear_model/_logistic.py:1321: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "/Users/tajahneiwilliams/opt/anaconda3/envs/PythonAdv/lib/python3.6/site-packages/sklearn/linear_model/_logistic.py:1321: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "/Users/tajahneiwilliams/opt/anaconda3/envs/PythonAdv/lib/python3.6/site-packages/sklearn/linear_model/_logistic.py:1321: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "/Users/tajahneiwilliams/opt/anaconda3/envs/PythonAdv/lib/python3.6/site-packages/sklearn/linear_model/_logistic.py:1321: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "/Users/tajahneiwilliams/opt/anaconda3/envs/PythonAdv/lib/python3.6/site-packages/sklearn/linear_model/_logistic.py:1321: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "/Users/tajahneiwilliams/opt/anaconda3/envs/PythonAdv/lib/python3.6/site-packages/sklearn/linear_model/_logistic.py:1321: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "/Users/tajahneiwilliams/opt/anaconda3/envs/PythonAdv/lib/python3.6/site-packages/sklearn/linear_model/_logistic.py:1321: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "/Users/tajahneiwilliams/opt/anaconda3/envs/PythonAdv/lib/python3.6/site-packages/sklearn/linear_model/_logistic.py:1321: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "/Users/tajahneiwilliams/opt/anaconda3/envs/PythonAdv/lib/python3.6/site-packages/sklearn/linear_model/_logistic.py:1321: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .... C=0.01, penalty=none, solver=sag, score=0.719, total=   0.0s\n",
      "[CV] C=0.01, penalty=none, solver=sag ................................\n",
      "[CV] .... C=0.01, penalty=none, solver=sag, score=0.767, total=   0.0s\n",
      "[CV] C=0.01, penalty=none, solver=sag ................................\n",
      "[CV] .... C=0.01, penalty=none, solver=sag, score=0.729, total=   0.0s\n",
      "[CV] C=0.01, penalty=none, solver=sag ................................\n",
      "[CV] .... C=0.01, penalty=none, solver=sag, score=0.752, total=   0.0s\n",
      "[CV] C=0.01, penalty=none, solver=sag ................................\n",
      "[CV] .... C=0.01, penalty=none, solver=sag, score=0.733, total=   0.0s\n",
      "[CV] C=0.01, penalty=none, solver=saga ...............................\n",
      "[CV] ... C=0.01, penalty=none, solver=saga, score=0.719, total=   0.0s\n",
      "[CV] C=0.01, penalty=none, solver=saga ...............................\n",
      "[CV] ... C=0.01, penalty=none, solver=saga, score=0.767, total=   0.0s\n",
      "[CV] C=0.01, penalty=none, solver=saga ...............................\n",
      "[CV] ... C=0.01, penalty=none, solver=saga, score=0.729, total=   0.0s\n",
      "[CV] C=0.01, penalty=none, solver=saga ...............................\n",
      "[CV] ... C=0.01, penalty=none, solver=saga, score=0.752, total=   0.0s\n",
      "[CV] C=0.01, penalty=none, solver=saga ...............................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tajahneiwilliams/opt/anaconda3/envs/PythonAdv/lib/python3.6/site-packages/sklearn/linear_model/_logistic.py:1321: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "/Users/tajahneiwilliams/opt/anaconda3/envs/PythonAdv/lib/python3.6/site-packages/sklearn/model_selection/_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/tajahneiwilliams/opt/anaconda3/envs/PythonAdv/lib/python3.6/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/tajahneiwilliams/opt/anaconda3/envs/PythonAdv/lib/python3.6/site-packages/sklearn/linear_model/_logistic.py\", line 1304, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/Users/tajahneiwilliams/opt/anaconda3/envs/PythonAdv/lib/python3.6/site-packages/sklearn/linear_model/_logistic.py\", line 443, in _check_solver\n",
      "    \"got %s penalty.\" % (solver, penalty))\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/tajahneiwilliams/opt/anaconda3/envs/PythonAdv/lib/python3.6/site-packages/sklearn/model_selection/_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/tajahneiwilliams/opt/anaconda3/envs/PythonAdv/lib/python3.6/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/tajahneiwilliams/opt/anaconda3/envs/PythonAdv/lib/python3.6/site-packages/sklearn/linear_model/_logistic.py\", line 1304, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/Users/tajahneiwilliams/opt/anaconda3/envs/PythonAdv/lib/python3.6/site-packages/sklearn/linear_model/_logistic.py\", line 443, in _check_solver\n",
      "    \"got %s penalty.\" % (solver, penalty))\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/tajahneiwilliams/opt/anaconda3/envs/PythonAdv/lib/python3.6/site-packages/sklearn/model_selection/_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/tajahneiwilliams/opt/anaconda3/envs/PythonAdv/lib/python3.6/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/tajahneiwilliams/opt/anaconda3/envs/PythonAdv/lib/python3.6/site-packages/sklearn/linear_model/_logistic.py\", line 1304, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/Users/tajahneiwilliams/opt/anaconda3/envs/PythonAdv/lib/python3.6/site-packages/sklearn/linear_model/_logistic.py\", line 443, in _check_solver\n",
      "    \"got %s penalty.\" % (solver, penalty))\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ... C=0.01, penalty=none, solver=saga, score=0.733, total=   0.0s\n",
      "[CV] C=0.1, penalty=l1, solver=newton-cg .............................\n",
      "[CV] ... C=0.1, penalty=l1, solver=newton-cg, score=nan, total=   0.0s\n",
      "[CV] C=0.1, penalty=l1, solver=newton-cg .............................\n",
      "[CV] ... C=0.1, penalty=l1, solver=newton-cg, score=nan, total=   0.0s\n",
      "[CV] C=0.1, penalty=l1, solver=newton-cg .............................\n",
      "[CV] ... C=0.1, penalty=l1, solver=newton-cg, score=nan, total=   0.0s\n",
      "[CV] C=0.1, penalty=l1, solver=newton-cg .............................\n",
      "[CV] ... C=0.1, penalty=l1, solver=newton-cg, score=nan, total=   0.0s\n",
      "[CV] C=0.1, penalty=l1, solver=newton-cg .............................\n",
      "[CV] ... C=0.1, penalty=l1, solver=newton-cg, score=nan, total=   0.0s\n",
      "[CV] C=0.1, penalty=l1, solver=lbfgs .................................\n",
      "[CV] ....... C=0.1, penalty=l1, solver=lbfgs, score=nan, total=   0.0s\n",
      "[CV] C=0.1, penalty=l1, solver=lbfgs .................................\n",
      "[CV] ....... C=0.1, penalty=l1, solver=lbfgs, score=nan, total=   0.0s\n",
      "[CV] C=0.1, penalty=l1, solver=lbfgs .................................\n",
      "[CV] ....... C=0.1, penalty=l1, solver=lbfgs, score=nan, total=   0.0s\n",
      "[CV] C=0.1, penalty=l1, solver=lbfgs .................................\n",
      "[CV] ....... C=0.1, penalty=l1, solver=lbfgs, score=nan, total=   0.0s\n",
      "[CV] C=0.1, penalty=l1, solver=lbfgs .................................\n",
      "[CV] ....... C=0.1, penalty=l1, solver=lbfgs, score=nan, total=   0.0s\n",
      "[CV] C=0.1, penalty=l1, solver=liblinear .............................\n",
      "[CV] . C=0.1, penalty=l1, solver=liblinear, score=0.690, total=   0.0s\n",
      "[CV] C=0.1, penalty=l1, solver=liblinear .............................\n",
      "[CV] . C=0.1, penalty=l1, solver=liblinear, score=0.700, total=   0.0s\n",
      "[CV] C=0.1, penalty=l1, solver=liblinear .............................\n",
      "[CV] . C=0.1, penalty=l1, solver=liblinear, score=0.738, total=   0.0s\n",
      "[CV] C=0.1, penalty=l1, solver=liblinear .............................\n",
      "[CV] . C=0.1, penalty=l1, solver=liblinear, score=0.771, total=   0.0s\n",
      "[CV] C=0.1, penalty=l1, solver=liblinear .............................\n",
      "[CV] . C=0.1, penalty=l1, solver=liblinear, score=0.695, total=   0.0s\n",
      "[CV] C=0.1, penalty=l1, solver=sag ...................................\n",
      "[CV] ......... C=0.1, penalty=l1, solver=sag, score=nan, total=   0.0s\n",
      "[CV] C=0.1, penalty=l1, solver=sag ...................................\n",
      "[CV] ......... C=0.1, penalty=l1, solver=sag, score=nan, total=   0.0s\n",
      "[CV] C=0.1, penalty=l1, solver=sag ...................................\n",
      "[CV] ......... C=0.1, penalty=l1, solver=sag, score=nan, total=   0.0s\n",
      "[CV] C=0.1, penalty=l1, solver=sag ...................................\n",
      "[CV] ......... C=0.1, penalty=l1, solver=sag, score=nan, total=   0.0s\n",
      "[CV] C=0.1, penalty=l1, solver=sag ...................................\n",
      "[CV] ......... C=0.1, penalty=l1, solver=sag, score=nan, total=   0.0s\n",
      "[CV] C=0.1, penalty=l1, solver=saga ..................................\n",
      "[CV] ...... C=0.1, penalty=l1, solver=saga, score=0.690, total=   0.0s\n",
      "[CV] C=0.1, penalty=l1, solver=saga ..................................\n",
      "[CV] ...... C=0.1, penalty=l1, solver=saga, score=0.690, total=   0.0s\n",
      "[CV] C=0.1, penalty=l1, solver=saga ..................................\n",
      "[CV] ...... C=0.1, penalty=l1, solver=saga, score=0.743, total=   0.0s\n",
      "[CV] C=0.1, penalty=l1, solver=saga ..................................\n",
      "[CV] ...... C=0.1, penalty=l1, solver=saga, score=0.771, total=   0.0s\n",
      "[CV] C=0.1, penalty=l1, solver=saga ..................................\n",
      "[CV] ...... C=0.1, penalty=l1, solver=saga, score=0.690, total=   0.0s\n",
      "[CV] C=0.1, penalty=l2, solver=newton-cg .............................\n",
      "[CV] . C=0.1, penalty=l2, solver=newton-cg, score=0.690, total=   0.0s\n",
      "[CV] C=0.1, penalty=l2, solver=newton-cg .............................\n",
      "[CV] . C=0.1, penalty=l2, solver=newton-cg, score=0.762, total=   0.0s\n",
      "[CV] C=0.1, penalty=l2, solver=newton-cg .............................\n",
      "[CV] . C=0.1, penalty=l2, solver=newton-cg, score=0.743, total=   0.0s\n",
      "[CV] C=0.1, penalty=l2, solver=newton-cg .............................\n",
      "[CV] . C=0.1, penalty=l2, solver=newton-cg, score=0.795, total=   0.0s\n",
      "[CV] C=0.1, penalty=l2, solver=newton-cg .............................\n",
      "[CV] . C=0.1, penalty=l2, solver=newton-cg, score=0.729, total=   0.0s\n",
      "[CV] C=0.1, penalty=l2, solver=lbfgs .................................\n",
      "[CV] ..... C=0.1, penalty=l2, solver=lbfgs, score=0.690, total=   0.0s\n",
      "[CV] C=0.1, penalty=l2, solver=lbfgs .................................\n",
      "[CV] ..... C=0.1, penalty=l2, solver=lbfgs, score=0.762, total=   0.0s\n",
      "[CV] C=0.1, penalty=l2, solver=lbfgs .................................\n",
      "[CV] ..... C=0.1, penalty=l2, solver=lbfgs, score=0.743, total=   0.0s\n",
      "[CV] C=0.1, penalty=l2, solver=lbfgs .................................\n",
      "[CV] ..... C=0.1, penalty=l2, solver=lbfgs, score=0.795, total=   0.0s\n",
      "[CV] C=0.1, penalty=l2, solver=lbfgs .................................\n",
      "[CV] ..... C=0.1, penalty=l2, solver=lbfgs, score=0.729, total=   0.0s\n",
      "[CV] C=0.1, penalty=l2, solver=liblinear .............................\n",
      "[CV] . C=0.1, penalty=l2, solver=liblinear, score=0.690, total=   0.0s\n",
      "[CV] C=0.1, penalty=l2, solver=liblinear .............................\n",
      "[CV] . C=0.1, penalty=l2, solver=liblinear, score=0.767, total=   0.0s\n",
      "[CV] C=0.1, penalty=l2, solver=liblinear .............................\n",
      "[CV] . C=0.1, penalty=l2, solver=liblinear, score=0.738, total=   0.0s\n",
      "[CV] C=0.1, penalty=l2, solver=liblinear .............................\n",
      "[CV] . C=0.1, penalty=l2, solver=liblinear, score=0.795, total=   0.0s\n",
      "[CV] C=0.1, penalty=l2, solver=liblinear .............................\n",
      "[CV] . C=0.1, penalty=l2, solver=liblinear, score=0.724, total=   0.0s\n",
      "[CV] C=0.1, penalty=l2, solver=sag ...................................\n",
      "[CV] ....... C=0.1, penalty=l2, solver=sag, score=0.690, total=   0.0s\n",
      "[CV] C=0.1, penalty=l2, solver=sag ...................................\n",
      "[CV] ....... C=0.1, penalty=l2, solver=sag, score=0.762, total=   0.0s\n",
      "[CV] C=0.1, penalty=l2, solver=sag ...................................\n",
      "[CV] ....... C=0.1, penalty=l2, solver=sag, score=0.743, total=   0.0s\n",
      "[CV] C=0.1, penalty=l2, solver=sag ...................................\n",
      "[CV] ....... C=0.1, penalty=l2, solver=sag, score=0.795, total=   0.0s\n",
      "[CV] C=0.1, penalty=l2, solver=sag ...................................\n",
      "[CV] ....... C=0.1, penalty=l2, solver=sag, score=0.729, total=   0.0s\n",
      "[CV] C=0.1, penalty=l2, solver=saga ..................................\n",
      "[CV] ...... C=0.1, penalty=l2, solver=saga, score=0.690, total=   0.0s\n",
      "[CV] C=0.1, penalty=l2, solver=saga ..................................\n",
      "[CV] ...... C=0.1, penalty=l2, solver=saga, score=0.762, total=   0.0s\n",
      "[CV] C=0.1, penalty=l2, solver=saga ..................................\n",
      "[CV] ...... C=0.1, penalty=l2, solver=saga, score=0.743, total=   0.0s\n",
      "[CV] C=0.1, penalty=l2, solver=saga ..................................\n",
      "[CV] ...... C=0.1, penalty=l2, solver=saga, score=0.795, total=   0.0s\n",
      "[CV] C=0.1, penalty=l2, solver=saga ..................................\n",
      "[CV] ...... C=0.1, penalty=l2, solver=saga, score=0.729, total=   0.0s\n",
      "[CV] C=0.1, penalty=elasticnet, solver=newton-cg .....................\n",
      "[CV]  C=0.1, penalty=elasticnet, solver=newton-cg, score=nan, total=   0.0s\n",
      "[CV] C=0.1, penalty=elasticnet, solver=newton-cg .....................\n",
      "[CV]  C=0.1, penalty=elasticnet, solver=newton-cg, score=nan, total=   0.0s\n",
      "[CV] C=0.1, penalty=elasticnet, solver=newton-cg .....................\n",
      "[CV]  C=0.1, penalty=elasticnet, solver=newton-cg, score=nan, total=   0.0s\n",
      "[CV] C=0.1, penalty=elasticnet, solver=newton-cg .....................\n",
      "[CV]  C=0.1, penalty=elasticnet, solver=newton-cg, score=nan, total=   0.0s\n",
      "[CV] C=0.1, penalty=elasticnet, solver=newton-cg .....................\n",
      "[CV]  C=0.1, penalty=elasticnet, solver=newton-cg, score=nan, total=   0.0s\n",
      "[CV] C=0.1, penalty=elasticnet, solver=lbfgs .........................\n",
      "[CV]  C=0.1, penalty=elasticnet, solver=lbfgs, score=nan, total=   0.0s\n",
      "[CV] C=0.1, penalty=elasticnet, solver=lbfgs .........................\n",
      "[CV]  C=0.1, penalty=elasticnet, solver=lbfgs, score=nan, total=   0.0s\n",
      "[CV] C=0.1, penalty=elasticnet, solver=lbfgs .........................\n",
      "[CV]  C=0.1, penalty=elasticnet, solver=lbfgs, score=nan, total=   0.0s\n",
      "[CV] C=0.1, penalty=elasticnet, solver=lbfgs .........................\n",
      "[CV]  C=0.1, penalty=elasticnet, solver=lbfgs, score=nan, total=   0.0s\n",
      "[CV] C=0.1, penalty=elasticnet, solver=lbfgs .........................\n",
      "[CV]  C=0.1, penalty=elasticnet, solver=lbfgs, score=nan, total=   0.0s\n",
      "[CV] C=0.1, penalty=elasticnet, solver=liblinear .....................\n",
      "[CV]  C=0.1, penalty=elasticnet, solver=liblinear, score=nan, total=   0.0s\n",
      "[CV] C=0.1, penalty=elasticnet, solver=liblinear .....................\n",
      "[CV]  C=0.1, penalty=elasticnet, solver=liblinear, score=nan, total=   0.0s\n",
      "[CV] C=0.1, penalty=elasticnet, solver=liblinear .....................\n",
      "[CV]  C=0.1, penalty=elasticnet, solver=liblinear, score=nan, total=   0.0s\n",
      "[CV] C=0.1, penalty=elasticnet, solver=liblinear .....................\n",
      "[CV]  C=0.1, penalty=elasticnet, solver=liblinear, score=nan, total=   0.0s\n",
      "[CV] C=0.1, penalty=elasticnet, solver=liblinear .....................\n",
      "[CV]  C=0.1, penalty=elasticnet, solver=liblinear, score=nan, total=   0.0s\n",
      "[CV] C=0.1, penalty=elasticnet, solver=sag ...........................\n",
      "[CV] . C=0.1, penalty=elasticnet, solver=sag, score=nan, total=   0.0s\n",
      "[CV] C=0.1, penalty=elasticnet, solver=sag ...........................\n",
      "[CV] . C=0.1, penalty=elasticnet, solver=sag, score=nan, total=   0.0s\n",
      "[CV] C=0.1, penalty=elasticnet, solver=sag ...........................\n",
      "[CV] . C=0.1, penalty=elasticnet, solver=sag, score=nan, total=   0.0s\n",
      "[CV] C=0.1, penalty=elasticnet, solver=sag ...........................\n",
      "[CV] . C=0.1, penalty=elasticnet, solver=sag, score=nan, total=   0.0s\n",
      "[CV] C=0.1, penalty=elasticnet, solver=sag ...........................\n",
      "[CV] . C=0.1, penalty=elasticnet, solver=sag, score=nan, total=   0.0s\n",
      "[CV] C=0.1, penalty=elasticnet, solver=saga ..........................\n",
      "[CV]  C=0.1, penalty=elasticnet, solver=saga, score=nan, total=   0.0s\n",
      "[CV] C=0.1, penalty=elasticnet, solver=saga ..........................\n",
      "[CV]  C=0.1, penalty=elasticnet, solver=saga, score=nan, total=   0.0s\n",
      "[CV] C=0.1, penalty=elasticnet, solver=saga ..........................\n",
      "[CV]  C=0.1, penalty=elasticnet, solver=saga, score=nan, total=   0.0s\n",
      "[CV] C=0.1, penalty=elasticnet, solver=saga ..........................\n",
      "[CV]  C=0.1, penalty=elasticnet, solver=saga, score=nan, total=   0.0s\n",
      "[CV] C=0.1, penalty=elasticnet, solver=saga ..........................\n",
      "[CV]  C=0.1, penalty=elasticnet, solver=saga, score=nan, total=   0.0s\n",
      "[CV] C=0.1, penalty=none, solver=newton-cg ...........................\n",
      "[CV]  C=0.1, penalty=none, solver=newton-cg, score=0.719, total=   0.0s\n",
      "[CV] C=0.1, penalty=none, solver=newton-cg ...........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tajahneiwilliams/opt/anaconda3/envs/PythonAdv/lib/python3.6/site-packages/sklearn/model_selection/_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/tajahneiwilliams/opt/anaconda3/envs/PythonAdv/lib/python3.6/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/tajahneiwilliams/opt/anaconda3/envs/PythonAdv/lib/python3.6/site-packages/sklearn/linear_model/_logistic.py\", line 1304, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/Users/tajahneiwilliams/opt/anaconda3/envs/PythonAdv/lib/python3.6/site-packages/sklearn/linear_model/_logistic.py\", line 443, in _check_solver\n",
      "    \"got %s penalty.\" % (solver, penalty))\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/tajahneiwilliams/opt/anaconda3/envs/PythonAdv/lib/python3.6/site-packages/sklearn/model_selection/_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/tajahneiwilliams/opt/anaconda3/envs/PythonAdv/lib/python3.6/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/tajahneiwilliams/opt/anaconda3/envs/PythonAdv/lib/python3.6/site-packages/sklearn/linear_model/_logistic.py\", line 1304, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/Users/tajahneiwilliams/opt/anaconda3/envs/PythonAdv/lib/python3.6/site-packages/sklearn/linear_model/_logistic.py\", line 443, in _check_solver\n",
      "    \"got %s penalty.\" % (solver, penalty))\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/tajahneiwilliams/opt/anaconda3/envs/PythonAdv/lib/python3.6/site-packages/sklearn/model_selection/_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/tajahneiwilliams/opt/anaconda3/envs/PythonAdv/lib/python3.6/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/tajahneiwilliams/opt/anaconda3/envs/PythonAdv/lib/python3.6/site-packages/sklearn/linear_model/_logistic.py\", line 1304, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/Users/tajahneiwilliams/opt/anaconda3/envs/PythonAdv/lib/python3.6/site-packages/sklearn/linear_model/_logistic.py\", line 450, in _check_solver\n",
      "    \" got solver={}.\".format(solver))\n",
      "ValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/tajahneiwilliams/opt/anaconda3/envs/PythonAdv/lib/python3.6/site-packages/sklearn/model_selection/_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/tajahneiwilliams/opt/anaconda3/envs/PythonAdv/lib/python3.6/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/tajahneiwilliams/opt/anaconda3/envs/PythonAdv/lib/python3.6/site-packages/sklearn/linear_model/_logistic.py\", line 1304, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/Users/tajahneiwilliams/opt/anaconda3/envs/PythonAdv/lib/python3.6/site-packages/sklearn/linear_model/_logistic.py\", line 443, in _check_solver\n",
      "    \"got %s penalty.\" % (solver, penalty))\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/tajahneiwilliams/opt/anaconda3/envs/PythonAdv/lib/python3.6/site-packages/sklearn/model_selection/_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/tajahneiwilliams/opt/anaconda3/envs/PythonAdv/lib/python3.6/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/tajahneiwilliams/opt/anaconda3/envs/PythonAdv/lib/python3.6/site-packages/sklearn/linear_model/_logistic.py\", line 1313, in fit\n",
      "    \" got (l1_ratio=%r)\" % self.l1_ratio)\n",
      "ValueError: l1_ratio must be between 0 and 1; got (l1_ratio=None)\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/tajahneiwilliams/opt/anaconda3/envs/PythonAdv/lib/python3.6/site-packages/sklearn/linear_model/_logistic.py:1321: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "/Users/tajahneiwilliams/opt/anaconda3/envs/PythonAdv/lib/python3.6/site-packages/sklearn/linear_model/_logistic.py:1321: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "/Users/tajahneiwilliams/opt/anaconda3/envs/PythonAdv/lib/python3.6/site-packages/sklearn/linear_model/_logistic.py:1321: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "/Users/tajahneiwilliams/opt/anaconda3/envs/PythonAdv/lib/python3.6/site-packages/sklearn/linear_model/_logistic.py:1321: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "/Users/tajahneiwilliams/opt/anaconda3/envs/PythonAdv/lib/python3.6/site-packages/sklearn/linear_model/_logistic.py:1321: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "/Users/tajahneiwilliams/opt/anaconda3/envs/PythonAdv/lib/python3.6/site-packages/sklearn/linear_model/_logistic.py:1321: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "/Users/tajahneiwilliams/opt/anaconda3/envs/PythonAdv/lib/python3.6/site-packages/sklearn/linear_model/_logistic.py:1321: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "/Users/tajahneiwilliams/opt/anaconda3/envs/PythonAdv/lib/python3.6/site-packages/sklearn/linear_model/_logistic.py:1321: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "/Users/tajahneiwilliams/opt/anaconda3/envs/PythonAdv/lib/python3.6/site-packages/sklearn/linear_model/_logistic.py:1321: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "/Users/tajahneiwilliams/opt/anaconda3/envs/PythonAdv/lib/python3.6/site-packages/sklearn/linear_model/_logistic.py:1321: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "/Users/tajahneiwilliams/opt/anaconda3/envs/PythonAdv/lib/python3.6/site-packages/sklearn/model_selection/_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/tajahneiwilliams/opt/anaconda3/envs/PythonAdv/lib/python3.6/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/tajahneiwilliams/opt/anaconda3/envs/PythonAdv/lib/python3.6/site-packages/sklearn/linear_model/_logistic.py\", line 1304, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/Users/tajahneiwilliams/opt/anaconda3/envs/PythonAdv/lib/python3.6/site-packages/sklearn/linear_model/_logistic.py\", line 454, in _check_solver\n",
      "    \"penalty='none' is not supported for the liblinear solver\"\n",
      "ValueError: penalty='none' is not supported for the liblinear solver\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/tajahneiwilliams/opt/anaconda3/envs/PythonAdv/lib/python3.6/site-packages/sklearn/linear_model/_logistic.py:1321: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  C=0.1, penalty=none, solver=newton-cg, score=0.767, total=   0.0s\n",
      "[CV] C=0.1, penalty=none, solver=newton-cg ...........................\n",
      "[CV]  C=0.1, penalty=none, solver=newton-cg, score=0.729, total=   0.0s\n",
      "[CV] C=0.1, penalty=none, solver=newton-cg ...........................\n",
      "[CV]  C=0.1, penalty=none, solver=newton-cg, score=0.752, total=   0.0s\n",
      "[CV] C=0.1, penalty=none, solver=newton-cg ...........................\n",
      "[CV]  C=0.1, penalty=none, solver=newton-cg, score=0.733, total=   0.0s\n",
      "[CV] C=0.1, penalty=none, solver=lbfgs ...............................\n",
      "[CV] ... C=0.1, penalty=none, solver=lbfgs, score=0.719, total=   0.0s\n",
      "[CV] C=0.1, penalty=none, solver=lbfgs ...............................\n",
      "[CV] ... C=0.1, penalty=none, solver=lbfgs, score=0.767, total=   0.0s\n",
      "[CV] C=0.1, penalty=none, solver=lbfgs ...............................\n",
      "[CV] ... C=0.1, penalty=none, solver=lbfgs, score=0.729, total=   0.0s\n",
      "[CV] C=0.1, penalty=none, solver=lbfgs ...............................\n",
      "[CV] ... C=0.1, penalty=none, solver=lbfgs, score=0.752, total=   0.0s\n",
      "[CV] C=0.1, penalty=none, solver=lbfgs ...............................\n",
      "[CV] ... C=0.1, penalty=none, solver=lbfgs, score=0.733, total=   0.0s\n",
      "[CV] C=0.1, penalty=none, solver=liblinear ...........................\n",
      "[CV] . C=0.1, penalty=none, solver=liblinear, score=nan, total=   0.0s\n",
      "[CV] C=0.1, penalty=none, solver=liblinear ...........................\n",
      "[CV] . C=0.1, penalty=none, solver=liblinear, score=nan, total=   0.0s\n",
      "[CV] C=0.1, penalty=none, solver=liblinear ...........................\n",
      "[CV] . C=0.1, penalty=none, solver=liblinear, score=nan, total=   0.0s\n",
      "[CV] C=0.1, penalty=none, solver=liblinear ...........................\n",
      "[CV] . C=0.1, penalty=none, solver=liblinear, score=nan, total=   0.0s\n",
      "[CV] C=0.1, penalty=none, solver=liblinear ...........................\n",
      "[CV] . C=0.1, penalty=none, solver=liblinear, score=nan, total=   0.0s\n",
      "[CV] C=0.1, penalty=none, solver=sag .................................\n",
      "[CV] ..... C=0.1, penalty=none, solver=sag, score=0.719, total=   0.0s\n",
      "[CV] C=0.1, penalty=none, solver=sag .................................\n",
      "[CV] ..... C=0.1, penalty=none, solver=sag, score=0.767, total=   0.0s\n",
      "[CV] C=0.1, penalty=none, solver=sag .................................\n",
      "[CV] ..... C=0.1, penalty=none, solver=sag, score=0.729, total=   0.0s\n",
      "[CV] C=0.1, penalty=none, solver=sag .................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tajahneiwilliams/opt/anaconda3/envs/PythonAdv/lib/python3.6/site-packages/sklearn/linear_model/_logistic.py:1321: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "/Users/tajahneiwilliams/opt/anaconda3/envs/PythonAdv/lib/python3.6/site-packages/sklearn/linear_model/_logistic.py:1321: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "/Users/tajahneiwilliams/opt/anaconda3/envs/PythonAdv/lib/python3.6/site-packages/sklearn/linear_model/_logistic.py:1321: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "/Users/tajahneiwilliams/opt/anaconda3/envs/PythonAdv/lib/python3.6/site-packages/sklearn/linear_model/_logistic.py:1321: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "/Users/tajahneiwilliams/opt/anaconda3/envs/PythonAdv/lib/python3.6/site-packages/sklearn/linear_model/_logistic.py:1321: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "/Users/tajahneiwilliams/opt/anaconda3/envs/PythonAdv/lib/python3.6/site-packages/sklearn/linear_model/_logistic.py:1321: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "/Users/tajahneiwilliams/opt/anaconda3/envs/PythonAdv/lib/python3.6/site-packages/sklearn/linear_model/_logistic.py:1321: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "/Users/tajahneiwilliams/opt/anaconda3/envs/PythonAdv/lib/python3.6/site-packages/sklearn/linear_model/_logistic.py:1321: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "/Users/tajahneiwilliams/opt/anaconda3/envs/PythonAdv/lib/python3.6/site-packages/sklearn/linear_model/_logistic.py:1321: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ..... C=0.1, penalty=none, solver=sag, score=0.752, total=   0.0s\n",
      "[CV] C=0.1, penalty=none, solver=sag .................................\n",
      "[CV] ..... C=0.1, penalty=none, solver=sag, score=0.733, total=   0.0s\n",
      "[CV] C=0.1, penalty=none, solver=saga ................................\n",
      "[CV] .... C=0.1, penalty=none, solver=saga, score=0.719, total=   0.0s\n",
      "[CV] C=0.1, penalty=none, solver=saga ................................\n",
      "[CV] .... C=0.1, penalty=none, solver=saga, score=0.767, total=   0.0s\n",
      "[CV] C=0.1, penalty=none, solver=saga ................................\n",
      "[CV] .... C=0.1, penalty=none, solver=saga, score=0.729, total=   0.0s\n",
      "[CV] C=0.1, penalty=none, solver=saga ................................\n",
      "[CV] .... C=0.1, penalty=none, solver=saga, score=0.752, total=   0.0s\n",
      "[CV] C=0.1, penalty=none, solver=saga ................................\n",
      "[CV] .... C=0.1, penalty=none, solver=saga, score=0.733, total=   0.0s\n",
      "[CV] C=1, penalty=l1, solver=newton-cg ...............................\n",
      "[CV] ..... C=1, penalty=l1, solver=newton-cg, score=nan, total=   0.0s\n",
      "[CV] C=1, penalty=l1, solver=newton-cg ...............................\n",
      "[CV] ..... C=1, penalty=l1, solver=newton-cg, score=nan, total=   0.0s\n",
      "[CV] C=1, penalty=l1, solver=newton-cg ...............................\n",
      "[CV] ..... C=1, penalty=l1, solver=newton-cg, score=nan, total=   0.0s\n",
      "[CV] C=1, penalty=l1, solver=newton-cg ...............................\n",
      "[CV] ..... C=1, penalty=l1, solver=newton-cg, score=nan, total=   0.0s\n",
      "[CV] C=1, penalty=l1, solver=newton-cg ...............................\n",
      "[CV] ..... C=1, penalty=l1, solver=newton-cg, score=nan, total=   0.0s\n",
      "[CV] C=1, penalty=l1, solver=lbfgs ...................................\n",
      "[CV] ......... C=1, penalty=l1, solver=lbfgs, score=nan, total=   0.0s\n",
      "[CV] C=1, penalty=l1, solver=lbfgs ...................................\n",
      "[CV] ......... C=1, penalty=l1, solver=lbfgs, score=nan, total=   0.0s\n",
      "[CV] C=1, penalty=l1, solver=lbfgs ...................................\n",
      "[CV] ......... C=1, penalty=l1, solver=lbfgs, score=nan, total=   0.0s\n",
      "[CV] C=1, penalty=l1, solver=lbfgs ...................................\n",
      "[CV] ......... C=1, penalty=l1, solver=lbfgs, score=nan, total=   0.0s\n",
      "[CV] C=1, penalty=l1, solver=lbfgs ...................................\n",
      "[CV] ......... C=1, penalty=l1, solver=lbfgs, score=nan, total=   0.0s\n",
      "[CV] C=1, penalty=l1, solver=liblinear ...............................\n",
      "[CV] ... C=1, penalty=l1, solver=liblinear, score=0.700, total=   0.0s\n",
      "[CV] C=1, penalty=l1, solver=liblinear ...............................\n",
      "[CV] ... C=1, penalty=l1, solver=liblinear, score=0.771, total=   0.0s\n",
      "[CV] C=1, penalty=l1, solver=liblinear ...............................\n",
      "[CV] ... C=1, penalty=l1, solver=liblinear, score=0.748, total=   0.0s\n",
      "[CV] C=1, penalty=l1, solver=liblinear ...............................\n",
      "[CV] ... C=1, penalty=l1, solver=liblinear, score=0.757, total=   0.0s\n",
      "[CV] C=1, penalty=l1, solver=liblinear ...............................\n",
      "[CV] ... C=1, penalty=l1, solver=liblinear, score=0.733, total=   0.0s\n",
      "[CV] C=1, penalty=l1, solver=sag .....................................\n",
      "[CV] ........... C=1, penalty=l1, solver=sag, score=nan, total=   0.0s\n",
      "[CV] C=1, penalty=l1, solver=sag .....................................\n",
      "[CV] ........... C=1, penalty=l1, solver=sag, score=nan, total=   0.0s\n",
      "[CV] C=1, penalty=l1, solver=sag .....................................\n",
      "[CV] ........... C=1, penalty=l1, solver=sag, score=nan, total=   0.0s\n",
      "[CV] C=1, penalty=l1, solver=sag .....................................\n",
      "[CV] ........... C=1, penalty=l1, solver=sag, score=nan, total=   0.0s\n",
      "[CV] C=1, penalty=l1, solver=sag .....................................\n",
      "[CV] ........... C=1, penalty=l1, solver=sag, score=nan, total=   0.0s\n",
      "[CV] C=1, penalty=l1, solver=saga ....................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tajahneiwilliams/opt/anaconda3/envs/PythonAdv/lib/python3.6/site-packages/sklearn/model_selection/_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/tajahneiwilliams/opt/anaconda3/envs/PythonAdv/lib/python3.6/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/tajahneiwilliams/opt/anaconda3/envs/PythonAdv/lib/python3.6/site-packages/sklearn/linear_model/_logistic.py\", line 1304, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/Users/tajahneiwilliams/opt/anaconda3/envs/PythonAdv/lib/python3.6/site-packages/sklearn/linear_model/_logistic.py\", line 443, in _check_solver\n",
      "    \"got %s penalty.\" % (solver, penalty))\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/tajahneiwilliams/opt/anaconda3/envs/PythonAdv/lib/python3.6/site-packages/sklearn/model_selection/_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/tajahneiwilliams/opt/anaconda3/envs/PythonAdv/lib/python3.6/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/tajahneiwilliams/opt/anaconda3/envs/PythonAdv/lib/python3.6/site-packages/sklearn/linear_model/_logistic.py\", line 1304, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/Users/tajahneiwilliams/opt/anaconda3/envs/PythonAdv/lib/python3.6/site-packages/sklearn/linear_model/_logistic.py\", line 443, in _check_solver\n",
      "    \"got %s penalty.\" % (solver, penalty))\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/tajahneiwilliams/opt/anaconda3/envs/PythonAdv/lib/python3.6/site-packages/sklearn/model_selection/_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/tajahneiwilliams/opt/anaconda3/envs/PythonAdv/lib/python3.6/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/tajahneiwilliams/opt/anaconda3/envs/PythonAdv/lib/python3.6/site-packages/sklearn/linear_model/_logistic.py\", line 1304, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/Users/tajahneiwilliams/opt/anaconda3/envs/PythonAdv/lib/python3.6/site-packages/sklearn/linear_model/_logistic.py\", line 443, in _check_solver\n",
      "    \"got %s penalty.\" % (solver, penalty))\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ........ C=1, penalty=l1, solver=saga, score=0.705, total=   0.0s\n",
      "[CV] C=1, penalty=l1, solver=saga ....................................\n",
      "[CV] ........ C=1, penalty=l1, solver=saga, score=0.767, total=   0.0s\n",
      "[CV] C=1, penalty=l1, solver=saga ....................................\n",
      "[CV] ........ C=1, penalty=l1, solver=saga, score=0.743, total=   0.0s\n",
      "[CV] C=1, penalty=l1, solver=saga ....................................\n",
      "[CV] ........ C=1, penalty=l1, solver=saga, score=0.757, total=   0.0s\n",
      "[CV] C=1, penalty=l1, solver=saga ....................................\n",
      "[CV] ........ C=1, penalty=l1, solver=saga, score=0.733, total=   0.0s\n",
      "[CV] C=1, penalty=l2, solver=newton-cg ...............................\n",
      "[CV] ... C=1, penalty=l2, solver=newton-cg, score=0.710, total=   0.0s\n",
      "[CV] C=1, penalty=l2, solver=newton-cg ...............................\n",
      "[CV] ... C=1, penalty=l2, solver=newton-cg, score=0.762, total=   0.0s\n",
      "[CV] C=1, penalty=l2, solver=newton-cg ...............................\n",
      "[CV] ... C=1, penalty=l2, solver=newton-cg, score=0.729, total=   0.0s\n",
      "[CV] C=1, penalty=l2, solver=newton-cg ...............................\n",
      "[CV] ... C=1, penalty=l2, solver=newton-cg, score=0.771, total=   0.0s\n",
      "[CV] C=1, penalty=l2, solver=newton-cg ...............................\n",
      "[CV] ... C=1, penalty=l2, solver=newton-cg, score=0.729, total=   0.0s\n",
      "[CV] C=1, penalty=l2, solver=lbfgs ...................................\n",
      "[CV] ....... C=1, penalty=l2, solver=lbfgs, score=0.710, total=   0.0s\n",
      "[CV] C=1, penalty=l2, solver=lbfgs ...................................\n",
      "[CV] ....... C=1, penalty=l2, solver=lbfgs, score=0.762, total=   0.0s\n",
      "[CV] C=1, penalty=l2, solver=lbfgs ...................................\n",
      "[CV] ....... C=1, penalty=l2, solver=lbfgs, score=0.729, total=   0.0s\n",
      "[CV] C=1, penalty=l2, solver=lbfgs ...................................\n",
      "[CV] ....... C=1, penalty=l2, solver=lbfgs, score=0.771, total=   0.0s\n",
      "[CV] C=1, penalty=l2, solver=lbfgs ...................................\n",
      "[CV] ....... C=1, penalty=l2, solver=lbfgs, score=0.729, total=   0.0s\n",
      "[CV] C=1, penalty=l2, solver=liblinear ...............................\n",
      "[CV] ... C=1, penalty=l2, solver=liblinear, score=0.705, total=   0.0s\n",
      "[CV] C=1, penalty=l2, solver=liblinear ...............................\n",
      "[CV] ... C=1, penalty=l2, solver=liblinear, score=0.762, total=   0.0s\n",
      "[CV] C=1, penalty=l2, solver=liblinear ...............................\n",
      "[CV] ... C=1, penalty=l2, solver=liblinear, score=0.733, total=   0.0s\n",
      "[CV] C=1, penalty=l2, solver=liblinear ...............................\n",
      "[CV] ... C=1, penalty=l2, solver=liblinear, score=0.767, total=   0.0s\n",
      "[CV] C=1, penalty=l2, solver=liblinear ...............................\n",
      "[CV] ... C=1, penalty=l2, solver=liblinear, score=0.724, total=   0.0s\n",
      "[CV] C=1, penalty=l2, solver=sag .....................................\n",
      "[CV] ......... C=1, penalty=l2, solver=sag, score=0.710, total=   0.0s\n",
      "[CV] C=1, penalty=l2, solver=sag .....................................\n",
      "[CV] ......... C=1, penalty=l2, solver=sag, score=0.762, total=   0.0s\n",
      "[CV] C=1, penalty=l2, solver=sag .....................................\n",
      "[CV] ......... C=1, penalty=l2, solver=sag, score=0.729, total=   0.0s\n",
      "[CV] C=1, penalty=l2, solver=sag .....................................\n",
      "[CV] ......... C=1, penalty=l2, solver=sag, score=0.771, total=   0.0s\n",
      "[CV] C=1, penalty=l2, solver=sag .....................................\n",
      "[CV] ......... C=1, penalty=l2, solver=sag, score=0.729, total=   0.0s\n",
      "[CV] C=1, penalty=l2, solver=saga ....................................\n",
      "[CV] ........ C=1, penalty=l2, solver=saga, score=0.710, total=   0.0s\n",
      "[CV] C=1, penalty=l2, solver=saga ....................................\n",
      "[CV] ........ C=1, penalty=l2, solver=saga, score=0.762, total=   0.0s\n",
      "[CV] C=1, penalty=l2, solver=saga ....................................\n",
      "[CV] ........ C=1, penalty=l2, solver=saga, score=0.729, total=   0.0s\n",
      "[CV] C=1, penalty=l2, solver=saga ....................................\n",
      "[CV] ........ C=1, penalty=l2, solver=saga, score=0.771, total=   0.0s\n",
      "[CV] C=1, penalty=l2, solver=saga ....................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tajahneiwilliams/opt/anaconda3/envs/PythonAdv/lib/python3.6/site-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/Users/tajahneiwilliams/opt/anaconda3/envs/PythonAdv/lib/python3.6/site-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/Users/tajahneiwilliams/opt/anaconda3/envs/PythonAdv/lib/python3.6/site-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/Users/tajahneiwilliams/opt/anaconda3/envs/PythonAdv/lib/python3.6/site-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/Users/tajahneiwilliams/opt/anaconda3/envs/PythonAdv/lib/python3.6/site-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/Users/tajahneiwilliams/opt/anaconda3/envs/PythonAdv/lib/python3.6/site-packages/sklearn/model_selection/_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/tajahneiwilliams/opt/anaconda3/envs/PythonAdv/lib/python3.6/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/tajahneiwilliams/opt/anaconda3/envs/PythonAdv/lib/python3.6/site-packages/sklearn/linear_model/_logistic.py\", line 1304, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/Users/tajahneiwilliams/opt/anaconda3/envs/PythonAdv/lib/python3.6/site-packages/sklearn/linear_model/_logistic.py\", line 443, in _check_solver\n",
      "    \"got %s penalty.\" % (solver, penalty))\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/tajahneiwilliams/opt/anaconda3/envs/PythonAdv/lib/python3.6/site-packages/sklearn/model_selection/_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/tajahneiwilliams/opt/anaconda3/envs/PythonAdv/lib/python3.6/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/tajahneiwilliams/opt/anaconda3/envs/PythonAdv/lib/python3.6/site-packages/sklearn/linear_model/_logistic.py\", line 1304, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/Users/tajahneiwilliams/opt/anaconda3/envs/PythonAdv/lib/python3.6/site-packages/sklearn/linear_model/_logistic.py\", line 443, in _check_solver\n",
      "    \"got %s penalty.\" % (solver, penalty))\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/tajahneiwilliams/opt/anaconda3/envs/PythonAdv/lib/python3.6/site-packages/sklearn/model_selection/_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/tajahneiwilliams/opt/anaconda3/envs/PythonAdv/lib/python3.6/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/tajahneiwilliams/opt/anaconda3/envs/PythonAdv/lib/python3.6/site-packages/sklearn/linear_model/_logistic.py\", line 1304, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/Users/tajahneiwilliams/opt/anaconda3/envs/PythonAdv/lib/python3.6/site-packages/sklearn/linear_model/_logistic.py\", line 450, in _check_solver\n",
      "    \" got solver={}.\".format(solver))\n",
      "ValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/tajahneiwilliams/opt/anaconda3/envs/PythonAdv/lib/python3.6/site-packages/sklearn/model_selection/_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/tajahneiwilliams/opt/anaconda3/envs/PythonAdv/lib/python3.6/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/tajahneiwilliams/opt/anaconda3/envs/PythonAdv/lib/python3.6/site-packages/sklearn/linear_model/_logistic.py\", line 1304, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/Users/tajahneiwilliams/opt/anaconda3/envs/PythonAdv/lib/python3.6/site-packages/sklearn/linear_model/_logistic.py\", line 443, in _check_solver\n",
      "    \"got %s penalty.\" % (solver, penalty))\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ........ C=1, penalty=l2, solver=saga, score=0.729, total=   0.0s\n",
      "[CV] C=1, penalty=elasticnet, solver=newton-cg .......................\n",
      "[CV]  C=1, penalty=elasticnet, solver=newton-cg, score=nan, total=   0.0s\n",
      "[CV] C=1, penalty=elasticnet, solver=newton-cg .......................\n",
      "[CV]  C=1, penalty=elasticnet, solver=newton-cg, score=nan, total=   0.0s\n",
      "[CV] C=1, penalty=elasticnet, solver=newton-cg .......................\n",
      "[CV]  C=1, penalty=elasticnet, solver=newton-cg, score=nan, total=   0.0s\n",
      "[CV] C=1, penalty=elasticnet, solver=newton-cg .......................\n",
      "[CV]  C=1, penalty=elasticnet, solver=newton-cg, score=nan, total=   0.0s\n",
      "[CV] C=1, penalty=elasticnet, solver=newton-cg .......................\n",
      "[CV]  C=1, penalty=elasticnet, solver=newton-cg, score=nan, total=   0.0s\n",
      "[CV] C=1, penalty=elasticnet, solver=lbfgs ...........................\n",
      "[CV] . C=1, penalty=elasticnet, solver=lbfgs, score=nan, total=   0.0s\n",
      "[CV] C=1, penalty=elasticnet, solver=lbfgs ...........................\n",
      "[CV] . C=1, penalty=elasticnet, solver=lbfgs, score=nan, total=   0.0s\n",
      "[CV] C=1, penalty=elasticnet, solver=lbfgs ...........................\n",
      "[CV] . C=1, penalty=elasticnet, solver=lbfgs, score=nan, total=   0.0s\n",
      "[CV] C=1, penalty=elasticnet, solver=lbfgs ...........................\n",
      "[CV] . C=1, penalty=elasticnet, solver=lbfgs, score=nan, total=   0.0s\n",
      "[CV] C=1, penalty=elasticnet, solver=lbfgs ...........................\n",
      "[CV] . C=1, penalty=elasticnet, solver=lbfgs, score=nan, total=   0.0s\n",
      "[CV] C=1, penalty=elasticnet, solver=liblinear .......................\n",
      "[CV]  C=1, penalty=elasticnet, solver=liblinear, score=nan, total=   0.0s\n",
      "[CV] C=1, penalty=elasticnet, solver=liblinear .......................\n",
      "[CV]  C=1, penalty=elasticnet, solver=liblinear, score=nan, total=   0.0s\n",
      "[CV] C=1, penalty=elasticnet, solver=liblinear .......................\n",
      "[CV]  C=1, penalty=elasticnet, solver=liblinear, score=nan, total=   0.0s\n",
      "[CV] C=1, penalty=elasticnet, solver=liblinear .......................\n",
      "[CV]  C=1, penalty=elasticnet, solver=liblinear, score=nan, total=   0.0s\n",
      "[CV] C=1, penalty=elasticnet, solver=liblinear .......................\n",
      "[CV]  C=1, penalty=elasticnet, solver=liblinear, score=nan, total=   0.0s\n",
      "[CV] C=1, penalty=elasticnet, solver=sag .............................\n",
      "[CV] ... C=1, penalty=elasticnet, solver=sag, score=nan, total=   0.0s\n",
      "[CV] C=1, penalty=elasticnet, solver=sag .............................\n",
      "[CV] ... C=1, penalty=elasticnet, solver=sag, score=nan, total=   0.0s\n",
      "[CV] C=1, penalty=elasticnet, solver=sag .............................\n",
      "[CV] ... C=1, penalty=elasticnet, solver=sag, score=nan, total=   0.0s\n",
      "[CV] C=1, penalty=elasticnet, solver=sag .............................\n",
      "[CV] ... C=1, penalty=elasticnet, solver=sag, score=nan, total=   0.0s\n",
      "[CV] C=1, penalty=elasticnet, solver=sag .............................\n",
      "[CV] ... C=1, penalty=elasticnet, solver=sag, score=nan, total=   0.0s\n",
      "[CV] C=1, penalty=elasticnet, solver=saga ............................\n",
      "[CV] .. C=1, penalty=elasticnet, solver=saga, score=nan, total=   0.0s\n",
      "[CV] C=1, penalty=elasticnet, solver=saga ............................\n",
      "[CV] .. C=1, penalty=elasticnet, solver=saga, score=nan, total=   0.0s\n",
      "[CV] C=1, penalty=elasticnet, solver=saga ............................\n",
      "[CV] .. C=1, penalty=elasticnet, solver=saga, score=nan, total=   0.0s\n",
      "[CV] C=1, penalty=elasticnet, solver=saga ............................\n",
      "[CV] .. C=1, penalty=elasticnet, solver=saga, score=nan, total=   0.0s\n",
      "[CV] C=1, penalty=elasticnet, solver=saga ............................\n",
      "[CV] .. C=1, penalty=elasticnet, solver=saga, score=nan, total=   0.0s\n",
      "[CV] C=1, penalty=none, solver=newton-cg .............................\n",
      "[CV] . C=1, penalty=none, solver=newton-cg, score=0.719, total=   0.0s\n",
      "[CV] C=1, penalty=none, solver=newton-cg .............................\n",
      "[CV] . C=1, penalty=none, solver=newton-cg, score=0.767, total=   0.0s\n",
      "[CV] C=1, penalty=none, solver=newton-cg .............................\n",
      "[CV] . C=1, penalty=none, solver=newton-cg, score=0.729, total=   0.0s\n",
      "[CV] C=1, penalty=none, solver=newton-cg .............................\n",
      "[CV] . C=1, penalty=none, solver=newton-cg, score=0.752, total=   0.0s\n",
      "[CV] C=1, penalty=none, solver=newton-cg .............................\n",
      "[CV] . C=1, penalty=none, solver=newton-cg, score=0.733, total=   0.0s\n",
      "[CV] C=1, penalty=none, solver=lbfgs .................................\n",
      "[CV] ..... C=1, penalty=none, solver=lbfgs, score=0.719, total=   0.0s\n",
      "[CV] C=1, penalty=none, solver=lbfgs .................................\n",
      "[CV] ..... C=1, penalty=none, solver=lbfgs, score=0.767, total=   0.0s\n",
      "[CV] C=1, penalty=none, solver=lbfgs .................................\n",
      "[CV] ..... C=1, penalty=none, solver=lbfgs, score=0.729, total=   0.0s\n",
      "[CV] C=1, penalty=none, solver=lbfgs .................................\n",
      "[CV] ..... C=1, penalty=none, solver=lbfgs, score=0.752, total=   0.0s\n",
      "[CV] C=1, penalty=none, solver=lbfgs .................................\n",
      "[CV] ..... C=1, penalty=none, solver=lbfgs, score=0.733, total=   0.0s\n",
      "[CV] C=1, penalty=none, solver=liblinear .............................\n",
      "[CV] ... C=1, penalty=none, solver=liblinear, score=nan, total=   0.0s\n",
      "[CV] C=1, penalty=none, solver=liblinear .............................\n",
      "[CV] ... C=1, penalty=none, solver=liblinear, score=nan, total=   0.0s\n",
      "[CV] C=1, penalty=none, solver=liblinear .............................\n",
      "[CV] ... C=1, penalty=none, solver=liblinear, score=nan, total=   0.0s\n",
      "[CV] C=1, penalty=none, solver=liblinear .............................\n",
      "[CV] ... C=1, penalty=none, solver=liblinear, score=nan, total=   0.0s\n",
      "[CV] C=1, penalty=none, solver=liblinear .............................\n",
      "[CV] ... C=1, penalty=none, solver=liblinear, score=nan, total=   0.0s\n",
      "[CV] C=1, penalty=none, solver=sag ...................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tajahneiwilliams/opt/anaconda3/envs/PythonAdv/lib/python3.6/site-packages/sklearn/model_selection/_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/tajahneiwilliams/opt/anaconda3/envs/PythonAdv/lib/python3.6/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/tajahneiwilliams/opt/anaconda3/envs/PythonAdv/lib/python3.6/site-packages/sklearn/linear_model/_logistic.py\", line 1313, in fit\n",
      "    \" got (l1_ratio=%r)\" % self.l1_ratio)\n",
      "ValueError: l1_ratio must be between 0 and 1; got (l1_ratio=None)\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/tajahneiwilliams/opt/anaconda3/envs/PythonAdv/lib/python3.6/site-packages/sklearn/model_selection/_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/tajahneiwilliams/opt/anaconda3/envs/PythonAdv/lib/python3.6/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/tajahneiwilliams/opt/anaconda3/envs/PythonAdv/lib/python3.6/site-packages/sklearn/linear_model/_logistic.py\", line 1304, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/Users/tajahneiwilliams/opt/anaconda3/envs/PythonAdv/lib/python3.6/site-packages/sklearn/linear_model/_logistic.py\", line 454, in _check_solver\n",
      "    \"penalty='none' is not supported for the liblinear solver\"\n",
      "ValueError: penalty='none' is not supported for the liblinear solver\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ....... C=1, penalty=none, solver=sag, score=0.719, total=   0.0s\n",
      "[CV] C=1, penalty=none, solver=sag ...................................\n",
      "[CV] ....... C=1, penalty=none, solver=sag, score=0.767, total=   0.0s\n",
      "[CV] C=1, penalty=none, solver=sag ...................................\n",
      "[CV] ....... C=1, penalty=none, solver=sag, score=0.729, total=   0.0s\n",
      "[CV] C=1, penalty=none, solver=sag ...................................\n",
      "[CV] ....... C=1, penalty=none, solver=sag, score=0.752, total=   0.0s\n",
      "[CV] C=1, penalty=none, solver=sag ...................................\n",
      "[CV] ....... C=1, penalty=none, solver=sag, score=0.733, total=   0.0s\n",
      "[CV] C=1, penalty=none, solver=saga ..................................\n",
      "[CV] ...... C=1, penalty=none, solver=saga, score=0.719, total=   0.0s\n",
      "[CV] C=1, penalty=none, solver=saga ..................................\n",
      "[CV] ...... C=1, penalty=none, solver=saga, score=0.767, total=   0.0s\n",
      "[CV] C=1, penalty=none, solver=saga ..................................\n",
      "[CV] ...... C=1, penalty=none, solver=saga, score=0.729, total=   0.0s\n",
      "[CV] C=1, penalty=none, solver=saga ..................................\n",
      "[CV] ...... C=1, penalty=none, solver=saga, score=0.752, total=   0.0s\n",
      "[CV] C=1, penalty=none, solver=saga ..................................\n",
      "[CV] ...... C=1, penalty=none, solver=saga, score=0.733, total=   0.0s\n",
      "[CV] C=2, penalty=l1, solver=newton-cg ...............................\n",
      "[CV] ..... C=2, penalty=l1, solver=newton-cg, score=nan, total=   0.0s\n",
      "[CV] C=2, penalty=l1, solver=newton-cg ...............................\n",
      "[CV] ..... C=2, penalty=l1, solver=newton-cg, score=nan, total=   0.0s\n",
      "[CV] C=2, penalty=l1, solver=newton-cg ...............................\n",
      "[CV] ..... C=2, penalty=l1, solver=newton-cg, score=nan, total=   0.0s\n",
      "[CV] C=2, penalty=l1, solver=newton-cg ...............................\n",
      "[CV] ..... C=2, penalty=l1, solver=newton-cg, score=nan, total=   0.0s\n",
      "[CV] C=2, penalty=l1, solver=newton-cg ...............................\n",
      "[CV] ..... C=2, penalty=l1, solver=newton-cg, score=nan, total=   0.0s\n",
      "[CV] C=2, penalty=l1, solver=lbfgs ...................................\n",
      "[CV] ......... C=2, penalty=l1, solver=lbfgs, score=nan, total=   0.0s\n",
      "[CV] C=2, penalty=l1, solver=lbfgs ...................................\n",
      "[CV] ......... C=2, penalty=l1, solver=lbfgs, score=nan, total=   0.0s\n",
      "[CV] C=2, penalty=l1, solver=lbfgs ...................................\n",
      "[CV] ......... C=2, penalty=l1, solver=lbfgs, score=nan, total=   0.0s\n",
      "[CV] C=2, penalty=l1, solver=lbfgs ...................................\n",
      "[CV] ......... C=2, penalty=l1, solver=lbfgs, score=nan, total=   0.0s\n",
      "[CV] C=2, penalty=l1, solver=lbfgs ...................................\n",
      "[CV] ......... C=2, penalty=l1, solver=lbfgs, score=nan, total=   0.0s\n",
      "[CV] C=2, penalty=l1, solver=liblinear ...............................\n",
      "[CV] ... C=2, penalty=l1, solver=liblinear, score=0.705, total=   0.0s\n",
      "[CV] C=2, penalty=l1, solver=liblinear ...............................\n",
      "[CV] ... C=2, penalty=l1, solver=liblinear, score=0.762, total=   0.0s\n",
      "[CV] C=2, penalty=l1, solver=liblinear ...............................\n",
      "[CV] ... C=2, penalty=l1, solver=liblinear, score=0.748, total=   0.0s\n",
      "[CV] C=2, penalty=l1, solver=liblinear ...............................\n",
      "[CV] ... C=2, penalty=l1, solver=liblinear, score=0.752, total=   0.0s\n",
      "[CV] C=2, penalty=l1, solver=liblinear ...............................\n",
      "[CV] ... C=2, penalty=l1, solver=liblinear, score=0.729, total=   0.0s\n",
      "[CV] C=2, penalty=l1, solver=sag .....................................\n",
      "[CV] ........... C=2, penalty=l1, solver=sag, score=nan, total=   0.0s\n",
      "[CV] C=2, penalty=l1, solver=sag .....................................\n",
      "[CV] ........... C=2, penalty=l1, solver=sag, score=nan, total=   0.0s\n",
      "[CV] C=2, penalty=l1, solver=sag .....................................\n",
      "[CV] ........... C=2, penalty=l1, solver=sag, score=nan, total=   0.0s\n",
      "[CV] C=2, penalty=l1, solver=sag .....................................\n",
      "[CV] ........... C=2, penalty=l1, solver=sag, score=nan, total=   0.0s\n",
      "[CV] C=2, penalty=l1, solver=sag .....................................\n",
      "[CV] ........... C=2, penalty=l1, solver=sag, score=nan, total=   0.0s\n",
      "[CV] C=2, penalty=l1, solver=saga ....................................\n",
      "[CV] ........ C=2, penalty=l1, solver=saga, score=0.705, total=   0.0s\n",
      "[CV] C=2, penalty=l1, solver=saga ....................................\n",
      "[CV] ........ C=2, penalty=l1, solver=saga, score=0.762, total=   0.0s\n",
      "[CV] C=2, penalty=l1, solver=saga ....................................\n",
      "[CV] ........ C=2, penalty=l1, solver=saga, score=0.738, total=   0.0s\n",
      "[CV] C=2, penalty=l1, solver=saga ....................................\n",
      "[CV] ........ C=2, penalty=l1, solver=saga, score=0.752, total=   0.0s\n",
      "[CV] C=2, penalty=l1, solver=saga ....................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tajahneiwilliams/opt/anaconda3/envs/PythonAdv/lib/python3.6/site-packages/sklearn/model_selection/_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/tajahneiwilliams/opt/anaconda3/envs/PythonAdv/lib/python3.6/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/tajahneiwilliams/opt/anaconda3/envs/PythonAdv/lib/python3.6/site-packages/sklearn/linear_model/_logistic.py\", line 1304, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/Users/tajahneiwilliams/opt/anaconda3/envs/PythonAdv/lib/python3.6/site-packages/sklearn/linear_model/_logistic.py\", line 443, in _check_solver\n",
      "    \"got %s penalty.\" % (solver, penalty))\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/tajahneiwilliams/opt/anaconda3/envs/PythonAdv/lib/python3.6/site-packages/sklearn/model_selection/_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/tajahneiwilliams/opt/anaconda3/envs/PythonAdv/lib/python3.6/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/tajahneiwilliams/opt/anaconda3/envs/PythonAdv/lib/python3.6/site-packages/sklearn/linear_model/_logistic.py\", line 1304, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/Users/tajahneiwilliams/opt/anaconda3/envs/PythonAdv/lib/python3.6/site-packages/sklearn/linear_model/_logistic.py\", line 443, in _check_solver\n",
      "    \"got %s penalty.\" % (solver, penalty))\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/tajahneiwilliams/opt/anaconda3/envs/PythonAdv/lib/python3.6/site-packages/sklearn/model_selection/_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/tajahneiwilliams/opt/anaconda3/envs/PythonAdv/lib/python3.6/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/tajahneiwilliams/opt/anaconda3/envs/PythonAdv/lib/python3.6/site-packages/sklearn/linear_model/_logistic.py\", line 1304, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/Users/tajahneiwilliams/opt/anaconda3/envs/PythonAdv/lib/python3.6/site-packages/sklearn/linear_model/_logistic.py\", line 443, in _check_solver\n",
      "    \"got %s penalty.\" % (solver, penalty))\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ........ C=2, penalty=l1, solver=saga, score=0.729, total=   0.0s\n",
      "[CV] C=2, penalty=l2, solver=newton-cg ...............................\n",
      "[CV] ... C=2, penalty=l2, solver=newton-cg, score=0.714, total=   0.0s\n",
      "[CV] C=2, penalty=l2, solver=newton-cg ...............................\n",
      "[CV] ... C=2, penalty=l2, solver=newton-cg, score=0.762, total=   0.0s\n",
      "[CV] C=2, penalty=l2, solver=newton-cg ...............................\n",
      "[CV] ... C=2, penalty=l2, solver=newton-cg, score=0.729, total=   0.0s\n",
      "[CV] C=2, penalty=l2, solver=newton-cg ...............................\n",
      "[CV] ... C=2, penalty=l2, solver=newton-cg, score=0.752, total=   0.0s\n",
      "[CV] C=2, penalty=l2, solver=newton-cg ...............................\n",
      "[CV] ... C=2, penalty=l2, solver=newton-cg, score=0.724, total=   0.0s\n",
      "[CV] C=2, penalty=l2, solver=lbfgs ...................................\n",
      "[CV] ....... C=2, penalty=l2, solver=lbfgs, score=0.714, total=   0.0s\n",
      "[CV] C=2, penalty=l2, solver=lbfgs ...................................\n",
      "[CV] ....... C=2, penalty=l2, solver=lbfgs, score=0.762, total=   0.0s\n",
      "[CV] C=2, penalty=l2, solver=lbfgs ...................................\n",
      "[CV] ....... C=2, penalty=l2, solver=lbfgs, score=0.729, total=   0.0s\n",
      "[CV] C=2, penalty=l2, solver=lbfgs ...................................\n",
      "[CV] ....... C=2, penalty=l2, solver=lbfgs, score=0.752, total=   0.0s\n",
      "[CV] C=2, penalty=l2, solver=lbfgs ...................................\n",
      "[CV] ....... C=2, penalty=l2, solver=lbfgs, score=0.724, total=   0.0s\n",
      "[CV] C=2, penalty=l2, solver=liblinear ...............................\n",
      "[CV] ... C=2, penalty=l2, solver=liblinear, score=0.714, total=   0.0s\n",
      "[CV] C=2, penalty=l2, solver=liblinear ...............................\n",
      "[CV] ... C=2, penalty=l2, solver=liblinear, score=0.762, total=   0.0s\n",
      "[CV] C=2, penalty=l2, solver=liblinear ...............................\n",
      "[CV] ... C=2, penalty=l2, solver=liblinear, score=0.729, total=   0.0s\n",
      "[CV] C=2, penalty=l2, solver=liblinear ...............................\n",
      "[CV] ... C=2, penalty=l2, solver=liblinear, score=0.752, total=   0.0s\n",
      "[CV] C=2, penalty=l2, solver=liblinear ...............................\n",
      "[CV] ... C=2, penalty=l2, solver=liblinear, score=0.729, total=   0.0s\n",
      "[CV] C=2, penalty=l2, solver=sag .....................................\n",
      "[CV] ......... C=2, penalty=l2, solver=sag, score=0.714, total=   0.0s\n",
      "[CV] C=2, penalty=l2, solver=sag .....................................\n",
      "[CV] ......... C=2, penalty=l2, solver=sag, score=0.762, total=   0.0s\n",
      "[CV] C=2, penalty=l2, solver=sag .....................................\n",
      "[CV] ......... C=2, penalty=l2, solver=sag, score=0.729, total=   0.0s\n",
      "[CV] C=2, penalty=l2, solver=sag .....................................\n",
      "[CV] ......... C=2, penalty=l2, solver=sag, score=0.752, total=   0.0s\n",
      "[CV] C=2, penalty=l2, solver=sag .....................................\n",
      "[CV] ......... C=2, penalty=l2, solver=sag, score=0.724, total=   0.0s\n",
      "[CV] C=2, penalty=l2, solver=saga ....................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tajahneiwilliams/opt/anaconda3/envs/PythonAdv/lib/python3.6/site-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/Users/tajahneiwilliams/opt/anaconda3/envs/PythonAdv/lib/python3.6/site-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/Users/tajahneiwilliams/opt/anaconda3/envs/PythonAdv/lib/python3.6/site-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/Users/tajahneiwilliams/opt/anaconda3/envs/PythonAdv/lib/python3.6/site-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/Users/tajahneiwilliams/opt/anaconda3/envs/PythonAdv/lib/python3.6/site-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/Users/tajahneiwilliams/opt/anaconda3/envs/PythonAdv/lib/python3.6/site-packages/sklearn/model_selection/_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/tajahneiwilliams/opt/anaconda3/envs/PythonAdv/lib/python3.6/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/tajahneiwilliams/opt/anaconda3/envs/PythonAdv/lib/python3.6/site-packages/sklearn/linear_model/_logistic.py\", line 1304, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/Users/tajahneiwilliams/opt/anaconda3/envs/PythonAdv/lib/python3.6/site-packages/sklearn/linear_model/_logistic.py\", line 443, in _check_solver\n",
      "    \"got %s penalty.\" % (solver, penalty))\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/tajahneiwilliams/opt/anaconda3/envs/PythonAdv/lib/python3.6/site-packages/sklearn/model_selection/_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/tajahneiwilliams/opt/anaconda3/envs/PythonAdv/lib/python3.6/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/tajahneiwilliams/opt/anaconda3/envs/PythonAdv/lib/python3.6/site-packages/sklearn/linear_model/_logistic.py\", line 1304, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/Users/tajahneiwilliams/opt/anaconda3/envs/PythonAdv/lib/python3.6/site-packages/sklearn/linear_model/_logistic.py\", line 443, in _check_solver\n",
      "    \"got %s penalty.\" % (solver, penalty))\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/tajahneiwilliams/opt/anaconda3/envs/PythonAdv/lib/python3.6/site-packages/sklearn/model_selection/_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/tajahneiwilliams/opt/anaconda3/envs/PythonAdv/lib/python3.6/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/tajahneiwilliams/opt/anaconda3/envs/PythonAdv/lib/python3.6/site-packages/sklearn/linear_model/_logistic.py\", line 1304, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/Users/tajahneiwilliams/opt/anaconda3/envs/PythonAdv/lib/python3.6/site-packages/sklearn/linear_model/_logistic.py\", line 450, in _check_solver\n",
      "    \" got solver={}.\".format(solver))\n",
      "ValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/tajahneiwilliams/opt/anaconda3/envs/PythonAdv/lib/python3.6/site-packages/sklearn/model_selection/_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/tajahneiwilliams/opt/anaconda3/envs/PythonAdv/lib/python3.6/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/tajahneiwilliams/opt/anaconda3/envs/PythonAdv/lib/python3.6/site-packages/sklearn/linear_model/_logistic.py\", line 1304, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/Users/tajahneiwilliams/opt/anaconda3/envs/PythonAdv/lib/python3.6/site-packages/sklearn/linear_model/_logistic.py\", line 443, in _check_solver\n",
      "    \"got %s penalty.\" % (solver, penalty))\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ........ C=2, penalty=l2, solver=saga, score=0.714, total=   0.0s\n",
      "[CV] C=2, penalty=l2, solver=saga ....................................\n",
      "[CV] ........ C=2, penalty=l2, solver=saga, score=0.762, total=   0.0s\n",
      "[CV] C=2, penalty=l2, solver=saga ....................................\n",
      "[CV] ........ C=2, penalty=l2, solver=saga, score=0.729, total=   0.0s\n",
      "[CV] C=2, penalty=l2, solver=saga ....................................\n",
      "[CV] ........ C=2, penalty=l2, solver=saga, score=0.752, total=   0.0s\n",
      "[CV] C=2, penalty=l2, solver=saga ....................................\n",
      "[CV] ........ C=2, penalty=l2, solver=saga, score=0.724, total=   0.0s\n",
      "[CV] C=2, penalty=elasticnet, solver=newton-cg .......................\n",
      "[CV]  C=2, penalty=elasticnet, solver=newton-cg, score=nan, total=   0.0s\n",
      "[CV] C=2, penalty=elasticnet, solver=newton-cg .......................\n",
      "[CV]  C=2, penalty=elasticnet, solver=newton-cg, score=nan, total=   0.0s\n",
      "[CV] C=2, penalty=elasticnet, solver=newton-cg .......................\n",
      "[CV]  C=2, penalty=elasticnet, solver=newton-cg, score=nan, total=   0.0s\n",
      "[CV] C=2, penalty=elasticnet, solver=newton-cg .......................\n",
      "[CV]  C=2, penalty=elasticnet, solver=newton-cg, score=nan, total=   0.0s\n",
      "[CV] C=2, penalty=elasticnet, solver=newton-cg .......................\n",
      "[CV]  C=2, penalty=elasticnet, solver=newton-cg, score=nan, total=   0.0s\n",
      "[CV] C=2, penalty=elasticnet, solver=lbfgs ...........................\n",
      "[CV] . C=2, penalty=elasticnet, solver=lbfgs, score=nan, total=   0.0s\n",
      "[CV] C=2, penalty=elasticnet, solver=lbfgs ...........................\n",
      "[CV] . C=2, penalty=elasticnet, solver=lbfgs, score=nan, total=   0.0s\n",
      "[CV] C=2, penalty=elasticnet, solver=lbfgs ...........................\n",
      "[CV] . C=2, penalty=elasticnet, solver=lbfgs, score=nan, total=   0.0s\n",
      "[CV] C=2, penalty=elasticnet, solver=lbfgs ...........................\n",
      "[CV] . C=2, penalty=elasticnet, solver=lbfgs, score=nan, total=   0.0s\n",
      "[CV] C=2, penalty=elasticnet, solver=lbfgs ...........................\n",
      "[CV] . C=2, penalty=elasticnet, solver=lbfgs, score=nan, total=   0.0s\n",
      "[CV] C=2, penalty=elasticnet, solver=liblinear .......................\n",
      "[CV]  C=2, penalty=elasticnet, solver=liblinear, score=nan, total=   0.0s\n",
      "[CV] C=2, penalty=elasticnet, solver=liblinear .......................\n",
      "[CV]  C=2, penalty=elasticnet, solver=liblinear, score=nan, total=   0.0s\n",
      "[CV] C=2, penalty=elasticnet, solver=liblinear .......................\n",
      "[CV]  C=2, penalty=elasticnet, solver=liblinear, score=nan, total=   0.0s\n",
      "[CV] C=2, penalty=elasticnet, solver=liblinear .......................\n",
      "[CV]  C=2, penalty=elasticnet, solver=liblinear, score=nan, total=   0.0s\n",
      "[CV] C=2, penalty=elasticnet, solver=liblinear .......................\n",
      "[CV]  C=2, penalty=elasticnet, solver=liblinear, score=nan, total=   0.0s\n",
      "[CV] C=2, penalty=elasticnet, solver=sag .............................\n",
      "[CV] ... C=2, penalty=elasticnet, solver=sag, score=nan, total=   0.0s\n",
      "[CV] C=2, penalty=elasticnet, solver=sag .............................\n",
      "[CV] ... C=2, penalty=elasticnet, solver=sag, score=nan, total=   0.0s\n",
      "[CV] C=2, penalty=elasticnet, solver=sag .............................\n",
      "[CV] ... C=2, penalty=elasticnet, solver=sag, score=nan, total=   0.0s\n",
      "[CV] C=2, penalty=elasticnet, solver=sag .............................\n",
      "[CV] ... C=2, penalty=elasticnet, solver=sag, score=nan, total=   0.0s\n",
      "[CV] C=2, penalty=elasticnet, solver=sag .............................\n",
      "[CV] ... C=2, penalty=elasticnet, solver=sag, score=nan, total=   0.0s\n",
      "[CV] C=2, penalty=elasticnet, solver=saga ............................\n",
      "[CV] .. C=2, penalty=elasticnet, solver=saga, score=nan, total=   0.0s\n",
      "[CV] C=2, penalty=elasticnet, solver=saga ............................\n",
      "[CV] .. C=2, penalty=elasticnet, solver=saga, score=nan, total=   0.0s\n",
      "[CV] C=2, penalty=elasticnet, solver=saga ............................\n",
      "[CV] .. C=2, penalty=elasticnet, solver=saga, score=nan, total=   0.0s\n",
      "[CV] C=2, penalty=elasticnet, solver=saga ............................\n",
      "[CV] .. C=2, penalty=elasticnet, solver=saga, score=nan, total=   0.0s\n",
      "[CV] C=2, penalty=elasticnet, solver=saga ............................\n",
      "[CV] .. C=2, penalty=elasticnet, solver=saga, score=nan, total=   0.0s\n",
      "[CV] C=2, penalty=none, solver=newton-cg .............................\n",
      "[CV] . C=2, penalty=none, solver=newton-cg, score=0.719, total=   0.0s\n",
      "[CV] C=2, penalty=none, solver=newton-cg .............................\n",
      "[CV] . C=2, penalty=none, solver=newton-cg, score=0.767, total=   0.0s\n",
      "[CV] C=2, penalty=none, solver=newton-cg .............................\n",
      "[CV] . C=2, penalty=none, solver=newton-cg, score=0.729, total=   0.0s\n",
      "[CV] C=2, penalty=none, solver=newton-cg .............................\n",
      "[CV] . C=2, penalty=none, solver=newton-cg, score=0.752, total=   0.0s\n",
      "[CV] C=2, penalty=none, solver=newton-cg .............................\n",
      "[CV] . C=2, penalty=none, solver=newton-cg, score=0.733, total=   0.0s\n",
      "[CV] C=2, penalty=none, solver=lbfgs .................................\n",
      "[CV] ..... C=2, penalty=none, solver=lbfgs, score=0.719, total=   0.0s\n",
      "[CV] C=2, penalty=none, solver=lbfgs .................................\n",
      "[CV] ..... C=2, penalty=none, solver=lbfgs, score=0.767, total=   0.0s\n",
      "[CV] C=2, penalty=none, solver=lbfgs .................................\n",
      "[CV] ..... C=2, penalty=none, solver=lbfgs, score=0.729, total=   0.0s\n",
      "[CV] C=2, penalty=none, solver=lbfgs .................................\n",
      "[CV] ..... C=2, penalty=none, solver=lbfgs, score=0.752, total=   0.0s\n",
      "[CV] C=2, penalty=none, solver=lbfgs .................................\n",
      "[CV] ..... C=2, penalty=none, solver=lbfgs, score=0.733, total=   0.0s\n",
      "[CV] C=2, penalty=none, solver=liblinear .............................\n",
      "[CV] ... C=2, penalty=none, solver=liblinear, score=nan, total=   0.0s\n",
      "[CV] C=2, penalty=none, solver=liblinear .............................\n",
      "[CV] ... C=2, penalty=none, solver=liblinear, score=nan, total=   0.0s\n",
      "[CV] C=2, penalty=none, solver=liblinear .............................\n",
      "[CV] ... C=2, penalty=none, solver=liblinear, score=nan, total=   0.0s\n",
      "[CV] C=2, penalty=none, solver=liblinear .............................\n",
      "[CV] ... C=2, penalty=none, solver=liblinear, score=nan, total=   0.0s\n",
      "[CV] C=2, penalty=none, solver=liblinear .............................\n",
      "[CV] ... C=2, penalty=none, solver=liblinear, score=nan, total=   0.0s\n",
      "[CV] C=2, penalty=none, solver=sag ...................................\n",
      "[CV] ....... C=2, penalty=none, solver=sag, score=0.719, total=   0.0s\n",
      "[CV] C=2, penalty=none, solver=sag ...................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tajahneiwilliams/opt/anaconda3/envs/PythonAdv/lib/python3.6/site-packages/sklearn/model_selection/_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/tajahneiwilliams/opt/anaconda3/envs/PythonAdv/lib/python3.6/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/tajahneiwilliams/opt/anaconda3/envs/PythonAdv/lib/python3.6/site-packages/sklearn/linear_model/_logistic.py\", line 1313, in fit\n",
      "    \" got (l1_ratio=%r)\" % self.l1_ratio)\n",
      "ValueError: l1_ratio must be between 0 and 1; got (l1_ratio=None)\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/tajahneiwilliams/opt/anaconda3/envs/PythonAdv/lib/python3.6/site-packages/sklearn/linear_model/_logistic.py:1321: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "/Users/tajahneiwilliams/opt/anaconda3/envs/PythonAdv/lib/python3.6/site-packages/sklearn/linear_model/_logistic.py:1321: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "/Users/tajahneiwilliams/opt/anaconda3/envs/PythonAdv/lib/python3.6/site-packages/sklearn/linear_model/_logistic.py:1321: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "/Users/tajahneiwilliams/opt/anaconda3/envs/PythonAdv/lib/python3.6/site-packages/sklearn/linear_model/_logistic.py:1321: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "/Users/tajahneiwilliams/opt/anaconda3/envs/PythonAdv/lib/python3.6/site-packages/sklearn/linear_model/_logistic.py:1321: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "/Users/tajahneiwilliams/opt/anaconda3/envs/PythonAdv/lib/python3.6/site-packages/sklearn/linear_model/_logistic.py:1321: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "/Users/tajahneiwilliams/opt/anaconda3/envs/PythonAdv/lib/python3.6/site-packages/sklearn/linear_model/_logistic.py:1321: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "/Users/tajahneiwilliams/opt/anaconda3/envs/PythonAdv/lib/python3.6/site-packages/sklearn/linear_model/_logistic.py:1321: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "/Users/tajahneiwilliams/opt/anaconda3/envs/PythonAdv/lib/python3.6/site-packages/sklearn/linear_model/_logistic.py:1321: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "/Users/tajahneiwilliams/opt/anaconda3/envs/PythonAdv/lib/python3.6/site-packages/sklearn/linear_model/_logistic.py:1321: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "/Users/tajahneiwilliams/opt/anaconda3/envs/PythonAdv/lib/python3.6/site-packages/sklearn/model_selection/_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/tajahneiwilliams/opt/anaconda3/envs/PythonAdv/lib/python3.6/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/tajahneiwilliams/opt/anaconda3/envs/PythonAdv/lib/python3.6/site-packages/sklearn/linear_model/_logistic.py\", line 1304, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/Users/tajahneiwilliams/opt/anaconda3/envs/PythonAdv/lib/python3.6/site-packages/sklearn/linear_model/_logistic.py\", line 454, in _check_solver\n",
      "    \"penalty='none' is not supported for the liblinear solver\"\n",
      "ValueError: penalty='none' is not supported for the liblinear solver\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/tajahneiwilliams/opt/anaconda3/envs/PythonAdv/lib/python3.6/site-packages/sklearn/linear_model/_logistic.py:1321: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "/Users/tajahneiwilliams/opt/anaconda3/envs/PythonAdv/lib/python3.6/site-packages/sklearn/linear_model/_logistic.py:1321: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ....... C=2, penalty=none, solver=sag, score=0.767, total=   0.0s\n",
      "[CV] C=2, penalty=none, solver=sag ...................................\n",
      "[CV] ....... C=2, penalty=none, solver=sag, score=0.729, total=   0.0s\n",
      "[CV] C=2, penalty=none, solver=sag ...................................\n",
      "[CV] ....... C=2, penalty=none, solver=sag, score=0.752, total=   0.0s\n",
      "[CV] C=2, penalty=none, solver=sag ...................................\n",
      "[CV] ....... C=2, penalty=none, solver=sag, score=0.733, total=   0.0s\n",
      "[CV] C=2, penalty=none, solver=saga ..................................\n",
      "[CV] ...... C=2, penalty=none, solver=saga, score=0.719, total=   0.0s\n",
      "[CV] C=2, penalty=none, solver=saga ..................................\n",
      "[CV] ...... C=2, penalty=none, solver=saga, score=0.767, total=   0.0s\n",
      "[CV] C=2, penalty=none, solver=saga ..................................\n",
      "[CV] ...... C=2, penalty=none, solver=saga, score=0.729, total=   0.0s\n",
      "[CV] C=2, penalty=none, solver=saga ..................................\n",
      "[CV] ...... C=2, penalty=none, solver=saga, score=0.752, total=   0.0s\n",
      "[CV] C=2, penalty=none, solver=saga ..................................\n",
      "[CV] ...... C=2, penalty=none, solver=saga, score=0.733, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tajahneiwilliams/opt/anaconda3/envs/PythonAdv/lib/python3.6/site-packages/sklearn/linear_model/_logistic.py:1321: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "/Users/tajahneiwilliams/opt/anaconda3/envs/PythonAdv/lib/python3.6/site-packages/sklearn/linear_model/_logistic.py:1321: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "/Users/tajahneiwilliams/opt/anaconda3/envs/PythonAdv/lib/python3.6/site-packages/sklearn/linear_model/_logistic.py:1321: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "/Users/tajahneiwilliams/opt/anaconda3/envs/PythonAdv/lib/python3.6/site-packages/sklearn/linear_model/_logistic.py:1321: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "/Users/tajahneiwilliams/opt/anaconda3/envs/PythonAdv/lib/python3.6/site-packages/sklearn/linear_model/_logistic.py:1321: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "/Users/tajahneiwilliams/opt/anaconda3/envs/PythonAdv/lib/python3.6/site-packages/sklearn/linear_model/_logistic.py:1321: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "/Users/tajahneiwilliams/opt/anaconda3/envs/PythonAdv/lib/python3.6/site-packages/sklearn/linear_model/_logistic.py:1321: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "/Users/tajahneiwilliams/opt/anaconda3/envs/PythonAdv/lib/python3.6/site-packages/sklearn/linear_model/_logistic.py:1321: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "[Parallel(n_jobs=1)]: Done 400 out of 400 | elapsed:    4.0s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=LogisticRegression(),\n",
       "             param_grid={'C': [0.01, 0.1, 1, 2],\n",
       "                         'penalty': ['l1', 'l2', 'elasticnet', 'none'],\n",
       "                         'solver': ['newton-cg', 'lbfgs', 'liblinear', 'sag',\n",
       "                                    'saga']},\n",
       "             verbose=3)"
      ]
     },
     "execution_count": 289,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Fit the model using the grid search estimator. \n",
    "grid.fit(X_train_minmax, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 0.1, 'penalty': 'l2', 'solver': 'newton-cg'}\n",
      "0.7438095238095238\n"
     ]
    }
   ],
   "source": [
    " #List the best parameters for this dataset\n",
    "print(grid.best_params_)\n",
    "#List the best score\n",
    "print(grid.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data Score: 0.7666666666666667\n",
      "Testing Data Score: 0.7142857142857143\n"
     ]
    }
   ],
   "source": [
    "print(f\"Training Data Score: {grid.score(X_train_minmax, y_train)}\")\n",
    "print(f\"Testing Data Score: {grid.score(X_test_minmax, y_test)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make predictions with the hypertuned model\n",
    "grid_predictions = grid.predict(X_test_minmax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 10 Predictions:   [1 1 0 0 0 0 0 1 0 0]\n",
      "First 10 Actual labels: [1, 0, 0, 0, 0, 0, 0, 1, 0, 1]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(f\"First 10 Predictions:   {grid_predictions[:10]}\")\n",
    "print(f\"First 10 Actual labels: {y_test[:10].tolist()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bad       0.69      0.77      0.73       173\n",
      "        good       0.75      0.66      0.70       177\n",
      "\n",
      "    accuracy                           0.71       350\n",
      "   macro avg       0.72      0.71      0.71       350\n",
      "weighted avg       0.72      0.71      0.71       350\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print (classification_report(y_test, grid_predictions,\n",
    "                            target_names=[\"bad\",\"good\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Import dependencies and plot confusion matrix\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "from sklearn.svm import SVC\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "clf = SVC(random_state=1)\n",
    "clf.fit(X_train_minmax, y_train)\n",
    "SVC(random_state=1)\n",
    "plot_confusion_matrix(clf, X_test_minmax, y_test)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
